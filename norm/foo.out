Starting dense_basis. Failed to load FSPS, only GP-SFH module will be available.
Loading MILES spectra and interpolating in metallicity: 
Generating 10.000 SFHs and their corresponding spectra for each Z:
z=  0
z=  1
z=  2
z=  3
z=  4
z=  5
z=  6
z=  7
z=  8
z=  9
z=  10
z=  11
z=  12
z=  13
z=  14
Reshaping...
Saving...
Modules prepared
GPU  prepared
Loading data...
Creating datasets...
16 components selected for the latent vectors
Calling accelerator...
DistributedType.NO
Training starts now...
Model defined
====> Epoch: 0 TRAINING Loss: 5.335e-02  VALIDATION Loss: 5.323e-02
====> Epoch: 1 TRAINING Loss: 5.097e-02  VALIDATION Loss: 4.865e-02
====> Epoch: 2 TRAINING Loss: 4.263e-02  VALIDATION Loss: 3.684e-02
====> Epoch: 3 TRAINING Loss: 3.329e-02  VALIDATION Loss: 3.036e-02
====> Epoch: 4 TRAINING Loss: 2.566e-02  VALIDATION Loss: 2.271e-02
====> Epoch: 5 TRAINING Loss: 2.143e-02  VALIDATION Loss: 2.094e-02
====> Epoch: 6 TRAINING Loss: 2.067e-02  VALIDATION Loss: 2.078e-02
====> Epoch: 7 TRAINING Loss: 2.049e-02  VALIDATION Loss: 2.045e-02
====> Epoch: 8 TRAINING Loss: 1.775e-02  VALIDATION Loss: 1.480e-02
====> Epoch: 9 TRAINING Loss: 9.838e-03  VALIDATION Loss: 6.684e-03
====> Epoch: 10 TRAINING Loss: 6.487e-03  VALIDATION Loss: 6.479e-03
====> Epoch: 11 TRAINING Loss: 6.391e-03  VALIDATION Loss: 6.356e-03
====> Epoch: 12 TRAINING Loss: 6.310e-03  VALIDATION Loss: 6.400e-03
====> Epoch: 13 TRAINING Loss: 6.223e-03  VALIDATION Loss: 5.922e-03
====> Epoch: 14 TRAINING Loss: 5.728e-03  VALIDATION Loss: 5.314e-03
====> Epoch: 15 TRAINING Loss: 4.884e-03  VALIDATION Loss: 4.482e-03
====> Epoch: 16 TRAINING Loss: 4.269e-03  VALIDATION Loss: 4.060e-03
====> Epoch: 17 TRAINING Loss: 3.857e-03  VALIDATION Loss: 3.671e-03
====> Epoch: 18 TRAINING Loss: 3.601e-03  VALIDATION Loss: 3.720e-03
====> Epoch: 19 TRAINING Loss: 3.720e-03  VALIDATION Loss: 3.679e-03
====> Epoch: 20 TRAINING Loss: 3.578e-03  VALIDATION Loss: 3.594e-03
====> Epoch: 21 TRAINING Loss: 3.549e-03  VALIDATION Loss: 3.619e-03
====> Epoch: 22 TRAINING Loss: 3.548e-03  VALIDATION Loss: 3.495e-03
====> Epoch: 23 TRAINING Loss: 3.494e-03  VALIDATION Loss: 3.762e-03
====> Epoch: 24 TRAINING Loss: 3.476e-03  VALIDATION Loss: 3.825e-03
====> Epoch: 25 TRAINING Loss: 3.400e-03  VALIDATION Loss: 3.263e-03
====> Epoch: 26 TRAINING Loss: 3.421e-03  VALIDATION Loss: 3.404e-03
====> Epoch: 27 TRAINING Loss: 3.377e-03  VALIDATION Loss: 3.235e-03
====> Epoch: 28 TRAINING Loss: 3.410e-03  VALIDATION Loss: 3.229e-03
====> Epoch: 29 TRAINING Loss: 3.299e-03  VALIDATION Loss: 3.571e-03
====> Epoch: 30 TRAINING Loss: 3.278e-03  VALIDATION Loss: 3.166e-03
====> Epoch: 31 TRAINING Loss: 3.401e-03  VALIDATION Loss: 3.274e-03
====> Epoch: 32 TRAINING Loss: 3.242e-03  VALIDATION Loss: 3.164e-03
====> Epoch: 33 TRAINING Loss: 3.258e-03  VALIDATION Loss: 3.212e-03
====> Epoch: 34 TRAINING Loss: 3.283e-03  VALIDATION Loss: 3.874e-03
====> Epoch: 35 TRAINING Loss: 3.343e-03  VALIDATION Loss: 3.507e-03
====> Epoch: 36 TRAINING Loss: 3.377e-03  VALIDATION Loss: 3.233e-03
====> Epoch: 37 TRAINING Loss: 3.245e-03  VALIDATION Loss: 3.133e-03
====> Epoch: 38 TRAINING Loss: 3.221e-03  VALIDATION Loss: 3.102e-03
====> Epoch: 39 TRAINING Loss: 3.286e-03  VALIDATION Loss: 3.117e-03
====> Epoch: 40 TRAINING Loss: 3.232e-03  VALIDATION Loss: 3.112e-03
====> Epoch: 41 TRAINING Loss: 3.233e-03  VALIDATION Loss: 3.231e-03
====> Epoch: 42 TRAINING Loss: 3.271e-03  VALIDATION Loss: 3.109e-03
====> Epoch: 43 TRAINING Loss: 3.252e-03  VALIDATION Loss: 3.164e-03
====> Epoch: 44 TRAINING Loss: 3.254e-03  VALIDATION Loss: 3.057e-03
====> Epoch: 45 TRAINING Loss: 3.166e-03  VALIDATION Loss: 3.415e-03
====> Epoch: 46 TRAINING Loss: 3.265e-03  VALIDATION Loss: 3.098e-03
====> Epoch: 47 TRAINING Loss: 3.203e-03  VALIDATION Loss: 2.993e-03
====> Epoch: 48 TRAINING Loss: 3.213e-03  VALIDATION Loss: 3.530e-03
====> Epoch: 49 TRAINING Loss: 3.185e-03  VALIDATION Loss: 3.090e-03
====> Epoch: 50 TRAINING Loss: 3.217e-03  VALIDATION Loss: 3.018e-03
====> Epoch: 51 TRAINING Loss: 3.210e-03  VALIDATION Loss: 3.204e-03
====> Epoch: 52 TRAINING Loss: 3.229e-03  VALIDATION Loss: 3.076e-03
====> Epoch: 53 TRAINING Loss: 3.159e-03  VALIDATION Loss: 3.293e-03
====> Epoch: 54 TRAINING Loss: 3.285e-03  VALIDATION Loss: 3.252e-03
====> Epoch: 55 TRAINING Loss: 3.197e-03  VALIDATION Loss: 3.051e-03
====> Epoch: 56 TRAINING Loss: 3.160e-03  VALIDATION Loss: 3.584e-03
====> Epoch: 57 TRAINING Loss: 3.201e-03  VALIDATION Loss: 2.981e-03
====> Epoch: 58 TRAINING Loss: 3.134e-03  VALIDATION Loss: 3.748e-03
====> Epoch: 59 TRAINING Loss: 3.130e-03  VALIDATION Loss: 2.941e-03
====> Epoch: 60 TRAINING Loss: 3.220e-03  VALIDATION Loss: 3.559e-03
====> Epoch: 61 TRAINING Loss: 3.120e-03  VALIDATION Loss: 2.963e-03
====> Epoch: 62 TRAINING Loss: 3.084e-03  VALIDATION Loss: 3.066e-03
====> Epoch: 63 TRAINING Loss: 3.068e-03  VALIDATION Loss: 3.122e-03
====> Epoch: 64 TRAINING Loss: 3.133e-03  VALIDATION Loss: 3.040e-03
====> Epoch: 65 TRAINING Loss: 3.071e-03  VALIDATION Loss: 3.265e-03
====> Epoch: 66 TRAINING Loss: 3.070e-03  VALIDATION Loss: 2.893e-03
====> Epoch: 67 TRAINING Loss: 3.075e-03  VALIDATION Loss: 2.916e-03
====> Epoch: 68 TRAINING Loss: 3.115e-03  VALIDATION Loss: 2.893e-03
====> Epoch: 69 TRAINING Loss: 3.013e-03  VALIDATION Loss: 3.397e-03
====> Epoch: 70 TRAINING Loss: 3.053e-03  VALIDATION Loss: 3.308e-03
====> Epoch: 71 TRAINING Loss: 3.075e-03  VALIDATION Loss: 3.247e-03
====> Epoch: 72 TRAINING Loss: 2.996e-03  VALIDATION Loss: 2.833e-03
====> Epoch: 73 TRAINING Loss: 3.012e-03  VALIDATION Loss: 2.878e-03
====> Epoch: 74 TRAINING Loss: 2.998e-03  VALIDATION Loss: 2.852e-03
====> Epoch: 75 TRAINING Loss: 3.059e-03  VALIDATION Loss: 2.954e-03
====> Epoch: 76 TRAINING Loss: 2.971e-03  VALIDATION Loss: 2.829e-03
====> Epoch: 77 TRAINING Loss: 2.975e-03  VALIDATION Loss: 2.846e-03
====> Epoch: 78 TRAINING Loss: 2.990e-03  VALIDATION Loss: 3.540e-03
====> Epoch: 79 TRAINING Loss: 3.000e-03  VALIDATION Loss: 2.757e-03
====> Epoch: 80 TRAINING Loss: 2.941e-03  VALIDATION Loss: 2.830e-03
====> Epoch: 81 TRAINING Loss: 2.897e-03  VALIDATION Loss: 2.825e-03
====> Epoch: 82 TRAINING Loss: 2.930e-03  VALIDATION Loss: 2.799e-03
====> Epoch: 83 TRAINING Loss: 2.989e-03  VALIDATION Loss: 2.918e-03
====> Epoch: 84 TRAINING Loss: 2.913e-03  VALIDATION Loss: 2.857e-03
====> Epoch: 85 TRAINING Loss: 2.838e-03  VALIDATION Loss: 2.724e-03
====> Epoch: 86 TRAINING Loss: 2.856e-03  VALIDATION Loss: 2.938e-03
====> Epoch: 87 TRAINING Loss: 2.874e-03  VALIDATION Loss: 2.747e-03
====> Epoch: 88 TRAINING Loss: 2.877e-03  VALIDATION Loss: 2.720e-03
====> Epoch: 89 TRAINING Loss: 2.840e-03  VALIDATION Loss: 3.232e-03
====> Epoch: 90 TRAINING Loss: 2.850e-03  VALIDATION Loss: 3.140e-03
====> Epoch: 91 TRAINING Loss: 2.783e-03  VALIDATION Loss: 2.809e-03
====> Epoch: 92 TRAINING Loss: 2.753e-03  VALIDATION Loss: 3.022e-03
====> Epoch: 93 TRAINING Loss: 2.812e-03  VALIDATION Loss: 2.721e-03
====> Epoch: 94 TRAINING Loss: 2.796e-03  VALIDATION Loss: 2.809e-03
====> Epoch: 95 TRAINING Loss: 2.814e-03  VALIDATION Loss: 3.061e-03
====> Epoch: 96 TRAINING Loss: 2.771e-03  VALIDATION Loss: 2.612e-03
====> Epoch: 97 TRAINING Loss: 2.764e-03  VALIDATION Loss: 2.648e-03
====> Epoch: 98 TRAINING Loss: 2.783e-03  VALIDATION Loss: 3.016e-03
====> Epoch: 99 TRAINING Loss: 2.735e-03  VALIDATION Loss: 2.640e-03
====> Epoch: 100 TRAINING Loss: 2.756e-03  VALIDATION Loss: 2.630e-03
====> Epoch: 101 TRAINING Loss: 2.746e-03  VALIDATION Loss: 2.708e-03
====> Epoch: 102 TRAINING Loss: 2.670e-03  VALIDATION Loss: 2.949e-03
====> Epoch: 103 TRAINING Loss: 2.714e-03  VALIDATION Loss: 2.627e-03
====> Epoch: 104 TRAINING Loss: 2.661e-03  VALIDATION Loss: 3.034e-03
====> Epoch: 105 TRAINING Loss: 2.625e-03  VALIDATION Loss: 2.575e-03
====> Epoch: 106 TRAINING Loss: 2.618e-03  VALIDATION Loss: 2.486e-03
====> Epoch: 107 TRAINING Loss: 2.644e-03  VALIDATION Loss: 2.506e-03
====> Epoch: 108 TRAINING Loss: 2.601e-03  VALIDATION Loss: 2.403e-03
====> Epoch: 109 TRAINING Loss: 2.637e-03  VALIDATION Loss: 2.456e-03
====> Epoch: 110 TRAINING Loss: 2.569e-03  VALIDATION Loss: 2.453e-03
====> Epoch: 111 TRAINING Loss: 2.632e-03  VALIDATION Loss: 2.437e-03
====> Epoch: 112 TRAINING Loss: 2.574e-03  VALIDATION Loss: 2.441e-03
====> Epoch: 113 TRAINING Loss: 2.538e-03  VALIDATION Loss: 2.542e-03
====> Epoch: 114 TRAINING Loss: 2.512e-03  VALIDATION Loss: 2.445e-03
====> Epoch: 115 TRAINING Loss: 2.516e-03  VALIDATION Loss: 2.381e-03
====> Epoch: 116 TRAINING Loss: 2.496e-03  VALIDATION Loss: 2.490e-03
====> Epoch: 117 TRAINING Loss: 2.463e-03  VALIDATION Loss: 2.530e-03
====> Epoch: 118 TRAINING Loss: 2.525e-03  VALIDATION Loss: 2.522e-03
====> Epoch: 119 TRAINING Loss: 2.433e-03  VALIDATION Loss: 2.260e-03
====> Epoch: 120 TRAINING Loss: 2.464e-03  VALIDATION Loss: 2.576e-03
====> Epoch: 121 TRAINING Loss: 2.483e-03  VALIDATION Loss: 2.667e-03
====> Epoch: 122 TRAINING Loss: 2.386e-03  VALIDATION Loss: 2.287e-03
====> Epoch: 123 TRAINING Loss: 2.413e-03  VALIDATION Loss: 2.464e-03
====> Epoch: 124 TRAINING Loss: 2.404e-03  VALIDATION Loss: 2.403e-03
====> Epoch: 125 TRAINING Loss: 2.386e-03  VALIDATION Loss: 2.314e-03
====> Epoch: 126 TRAINING Loss: 2.282e-03  VALIDATION Loss: 2.767e-03
====> Epoch: 127 TRAINING Loss: 2.363e-03  VALIDATION Loss: 2.247e-03
====> Epoch: 128 TRAINING Loss: 2.362e-03  VALIDATION Loss: 2.615e-03
====> Epoch: 129 TRAINING Loss: 2.352e-03  VALIDATION Loss: 2.207e-03
====> Epoch: 130 TRAINING Loss: 2.271e-03  VALIDATION Loss: 2.286e-03
====> Epoch: 131 TRAINING Loss: 2.281e-03  VALIDATION Loss: 2.351e-03
====> Epoch: 132 TRAINING Loss: 2.307e-03  VALIDATION Loss: 2.376e-03
====> Epoch: 133 TRAINING Loss: 2.234e-03  VALIDATION Loss: 2.213e-03
====> Epoch: 134 TRAINING Loss: 2.231e-03  VALIDATION Loss: 2.219e-03
====> Epoch: 135 TRAINING Loss: 2.319e-03  VALIDATION Loss: 2.221e-03
====> Epoch: 136 TRAINING Loss: 2.235e-03  VALIDATION Loss: 2.166e-03
====> Epoch: 137 TRAINING Loss: 2.210e-03  VALIDATION Loss: 2.454e-03
====> Epoch: 138 TRAINING Loss: 2.221e-03  VALIDATION Loss: 2.192e-03
====> Epoch: 139 TRAINING Loss: 2.156e-03  VALIDATION Loss: 2.104e-03
====> Epoch: 140 TRAINING Loss: 2.192e-03  VALIDATION Loss: 2.331e-03
====> Epoch: 141 TRAINING Loss: 2.185e-03  VALIDATION Loss: 2.413e-03
====> Epoch: 142 TRAINING Loss: 2.136e-03  VALIDATION Loss: 2.198e-03
====> Epoch: 143 TRAINING Loss: 2.139e-03  VALIDATION Loss: 2.276e-03
====> Epoch: 144 TRAINING Loss: 2.176e-03  VALIDATION Loss: 2.116e-03
====> Epoch: 145 TRAINING Loss: 2.125e-03  VALIDATION Loss: 2.183e-03
====> Epoch: 146 TRAINING Loss: 2.137e-03  VALIDATION Loss: 2.204e-03
====> Epoch: 147 TRAINING Loss: 2.074e-03  VALIDATION Loss: 1.970e-03
====> Epoch: 148 TRAINING Loss: 2.032e-03  VALIDATION Loss: 2.040e-03
====> Epoch: 149 TRAINING Loss: 2.052e-03  VALIDATION Loss: 1.990e-03
====> Epoch: 150 TRAINING Loss: 2.043e-03  VALIDATION Loss: 1.952e-03
====> Epoch: 151 TRAINING Loss: 2.023e-03  VALIDATION Loss: 1.935e-03
====> Epoch: 152 TRAINING Loss: 2.072e-03  VALIDATION Loss: 2.028e-03
====> Epoch: 153 TRAINING Loss: 2.028e-03  VALIDATION Loss: 2.000e-03
====> Epoch: 154 TRAINING Loss: 1.968e-03  VALIDATION Loss: 2.006e-03
====> Epoch: 155 TRAINING Loss: 2.008e-03  VALIDATION Loss: 2.008e-03
====> Epoch: 156 TRAINING Loss: 1.983e-03  VALIDATION Loss: 1.899e-03
====> Epoch: 157 TRAINING Loss: 1.997e-03  VALIDATION Loss: 2.073e-03
====> Epoch: 158 TRAINING Loss: 2.006e-03  VALIDATION Loss: 1.990e-03
====> Epoch: 159 TRAINING Loss: 1.932e-03  VALIDATION Loss: 1.882e-03
====> Epoch: 160 TRAINING Loss: 1.957e-03  VALIDATION Loss: 1.933e-03
====> Epoch: 161 TRAINING Loss: 1.932e-03  VALIDATION Loss: 1.896e-03
====> Epoch: 162 TRAINING Loss: 1.951e-03  VALIDATION Loss: 1.887e-03
====> Epoch: 163 TRAINING Loss: 1.943e-03  VALIDATION Loss: 1.918e-03
====> Epoch: 164 TRAINING Loss: 1.923e-03  VALIDATION Loss: 1.927e-03
====> Epoch: 165 TRAINING Loss: 1.939e-03  VALIDATION Loss: 1.876e-03
====> Epoch: 166 TRAINING Loss: 1.918e-03  VALIDATION Loss: 2.054e-03
====> Epoch: 167 TRAINING Loss: 1.906e-03  VALIDATION Loss: 1.932e-03
====> Epoch: 168 TRAINING Loss: 1.895e-03  VALIDATION Loss: 1.806e-03
====> Epoch: 169 TRAINING Loss: 1.867e-03  VALIDATION Loss: 2.073e-03
====> Epoch: 170 TRAINING Loss: 1.892e-03  VALIDATION Loss: 1.935e-03
====> Epoch: 171 TRAINING Loss: 1.911e-03  VALIDATION Loss: 1.839e-03
====> Epoch: 172 TRAINING Loss: 1.883e-03  VALIDATION Loss: 1.866e-03
====> Epoch: 173 TRAINING Loss: 1.845e-03  VALIDATION Loss: 1.886e-03
====> Epoch: 174 TRAINING Loss: 1.848e-03  VALIDATION Loss: 1.928e-03
====> Epoch: 175 TRAINING Loss: 1.871e-03  VALIDATION Loss: 1.899e-03
====> Epoch: 176 TRAINING Loss: 1.863e-03  VALIDATION Loss: 1.825e-03
====> Epoch: 177 TRAINING Loss: 1.819e-03  VALIDATION Loss: 1.762e-03
====> Epoch: 178 TRAINING Loss: 1.826e-03  VALIDATION Loss: 1.819e-03
====> Epoch: 179 TRAINING Loss: 1.818e-03  VALIDATION Loss: 1.820e-03
====> Epoch: 180 TRAINING Loss: 1.805e-03  VALIDATION Loss: 1.761e-03
====> Epoch: 181 TRAINING Loss: 1.805e-03  VALIDATION Loss: 1.769e-03
====> Epoch: 182 TRAINING Loss: 1.794e-03  VALIDATION Loss: 1.743e-03
====> Epoch: 183 TRAINING Loss: 1.767e-03  VALIDATION Loss: 1.764e-03
====> Epoch: 184 TRAINING Loss: 1.775e-03  VALIDATION Loss: 1.750e-03
====> Epoch: 185 TRAINING Loss: 1.761e-03  VALIDATION Loss: 1.733e-03
====> Epoch: 186 TRAINING Loss: 1.740e-03  VALIDATION Loss: 1.797e-03
====> Epoch: 187 TRAINING Loss: 1.756e-03  VALIDATION Loss: 1.744e-03
====> Epoch: 188 TRAINING Loss: 1.724e-03  VALIDATION Loss: 1.837e-03
====> Epoch: 189 TRAINING Loss: 1.761e-03  VALIDATION Loss: 1.709e-03
====> Epoch: 190 TRAINING Loss: 1.733e-03  VALIDATION Loss: 1.707e-03
====> Epoch: 191 TRAINING Loss: 1.724e-03  VALIDATION Loss: 1.717e-03
====> Epoch: 192 TRAINING Loss: 1.699e-03  VALIDATION Loss: 1.738e-03
====> Epoch: 193 TRAINING Loss: 1.707e-03  VALIDATION Loss: 1.700e-03
====> Epoch: 194 TRAINING Loss: 1.736e-03  VALIDATION Loss: 1.711e-03
====> Epoch: 195 TRAINING Loss: 1.696e-03  VALIDATION Loss: 1.667e-03
====> Epoch: 196 TRAINING Loss: 1.691e-03  VALIDATION Loss: 1.737e-03
====> Epoch: 197 TRAINING Loss: 1.685e-03  VALIDATION Loss: 1.681e-03
====> Epoch: 198 TRAINING Loss: 1.666e-03  VALIDATION Loss: 1.819e-03
====> Epoch: 199 TRAINING Loss: 1.699e-03  VALIDATION Loss: 1.643e-03
====> Epoch: 200 TRAINING Loss: 1.645e-03  VALIDATION Loss: 1.637e-03
====> Epoch: 201 TRAINING Loss: 1.664e-03  VALIDATION Loss: 1.679e-03
====> Epoch: 202 TRAINING Loss: 1.656e-03  VALIDATION Loss: 1.633e-03
====> Epoch: 203 TRAINING Loss: 1.644e-03  VALIDATION Loss: 1.636e-03
====> Epoch: 204 TRAINING Loss: 1.669e-03  VALIDATION Loss: 1.615e-03
====> Epoch: 205 TRAINING Loss: 1.620e-03  VALIDATION Loss: 1.627e-03
====> Epoch: 206 TRAINING Loss: 1.642e-03  VALIDATION Loss: 1.624e-03
====> Epoch: 207 TRAINING Loss: 1.634e-03  VALIDATION Loss: 1.619e-03
====> Epoch: 208 TRAINING Loss: 1.631e-03  VALIDATION Loss: 1.617e-03
====> Epoch: 209 TRAINING Loss: 1.606e-03  VALIDATION Loss: 1.600e-03
====> Epoch: 210 TRAINING Loss: 1.618e-03  VALIDATION Loss: 1.651e-03
====> Epoch: 211 TRAINING Loss: 1.616e-03  VALIDATION Loss: 1.601e-03
====> Epoch: 212 TRAINING Loss: 1.593e-03  VALIDATION Loss: 1.624e-03
====> Epoch: 213 TRAINING Loss: 1.594e-03  VALIDATION Loss: 1.616e-03
====> Epoch: 214 TRAINING Loss: 1.616e-03  VALIDATION Loss: 1.604e-03
====> Epoch: 215 TRAINING Loss: 1.586e-03  VALIDATION Loss: 1.632e-03
====> Epoch: 216 TRAINING Loss: 1.573e-03  VALIDATION Loss: 1.596e-03
====> Epoch: 217 TRAINING Loss: 1.578e-03  VALIDATION Loss: 1.571e-03
====> Epoch: 218 TRAINING Loss: 1.578e-03  VALIDATION Loss: 1.582e-03
====> Epoch: 219 TRAINING Loss: 1.586e-03  VALIDATION Loss: 1.572e-03
====> Epoch: 220 TRAINING Loss: 1.584e-03  VALIDATION Loss: 1.604e-03
====> Epoch: 221 TRAINING Loss: 1.558e-03  VALIDATION Loss: 1.571e-03
====> Epoch: 222 TRAINING Loss: 1.560e-03  VALIDATION Loss: 1.588e-03
====> Epoch: 223 TRAINING Loss: 1.560e-03  VALIDATION Loss: 1.559e-03
====> Epoch: 224 TRAINING Loss: 1.555e-03  VALIDATION Loss: 1.556e-03
====> Epoch: 225 TRAINING Loss: 1.561e-03  VALIDATION Loss: 1.556e-03
====> Epoch: 226 TRAINING Loss: 1.557e-03  VALIDATION Loss: 1.545e-03
====> Epoch: 227 TRAINING Loss: 1.541e-03  VALIDATION Loss: 1.544e-03
====> Epoch: 228 TRAINING Loss: 1.559e-03  VALIDATION Loss: 1.559e-03
====> Epoch: 229 TRAINING Loss: 1.550e-03  VALIDATION Loss: 1.568e-03
====> Epoch: 230 TRAINING Loss: 1.550e-03  VALIDATION Loss: 1.539e-03
====> Epoch: 231 TRAINING Loss: 1.546e-03  VALIDATION Loss: 1.536e-03
====> Epoch: 232 TRAINING Loss: 1.521e-03  VALIDATION Loss: 1.539e-03
====> Epoch: 233 TRAINING Loss: 1.530e-03  VALIDATION Loss: 1.535e-03
====> Epoch: 234 TRAINING Loss: 1.530e-03  VALIDATION Loss: 1.535e-03
====> Epoch: 235 TRAINING Loss: 1.550e-03  VALIDATION Loss: 1.535e-03
====> Epoch: 236 TRAINING Loss: 1.547e-03  VALIDATION Loss: 1.530e-03
====> Epoch: 237 TRAINING Loss: 1.525e-03  VALIDATION Loss: 1.532e-03
====> Epoch: 238 TRAINING Loss: 1.521e-03  VALIDATION Loss: 1.536e-03
====> Epoch: 239 TRAINING Loss: 1.523e-03  VALIDATION Loss: 1.525e-03
====> Epoch: 240 TRAINING Loss: 1.524e-03  VALIDATION Loss: 1.526e-03
====> Epoch: 241 TRAINING Loss: 1.525e-03  VALIDATION Loss: 1.528e-03
====> Epoch: 242 TRAINING Loss: 1.531e-03  VALIDATION Loss: 1.528e-03
====> Epoch: 243 TRAINING Loss: 1.495e-03  VALIDATION Loss: 1.526e-03
====> Epoch: 244 TRAINING Loss: 1.510e-03  VALIDATION Loss: 1.523e-03
====> Epoch: 245 TRAINING Loss: 1.499e-03  VALIDATION Loss: 1.523e-03
====> Epoch: 246 TRAINING Loss: 1.512e-03  VALIDATION Loss: 1.524e-03
====> Epoch: 247 TRAINING Loss: 1.510e-03  VALIDATION Loss: 1.523e-03
====> Epoch: 248 TRAINING Loss: 1.502e-03  VALIDATION Loss: 1.527e-03
====> Epoch: 249 TRAINING Loss: 1.539e-03  VALIDATION Loss: 1.526e-03
Training has finished
Model saved
n_epochs: 250, batch_size: 128, lr: 5e-04
Modules prepared
cuda:0  prepared
Loading data...
Shuffling...
Dataset prepared
16 components selected for the latent vectors
Shape of the test set:  (15000, 4300)
Calling accelerator...
DistributedType.NO
Loading model...
Testing starts now...
Saving latents and predicted percentiles...
Loading modules
cuda:0  prepared
Loading data...
Creating dataset and calling accelerator
Shape of the dataset:  (150000, 4300)
Loading module trained with latents of  16  components
Getting latent vectors and predicted percentiles
Saving spectra, percentiles, latents and predicted percentiles
