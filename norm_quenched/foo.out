Starting dense_basis. Failed to load FSPS, only GP-SFH module will be available.
Loading MILES spectra and interpolating in metallicity: 
Generating 10.000 SFHs and their corresponding spectra for each Z:
z=  0
z=  1
z=  2
z=  3
z=  4
z=  5
z=  6
z=  7
z=  8
z=  9
z=  10
z=  11
z=  12
z=  13
z=  14
Reshaping...
Saving...
Modules prepared
GPU  prepared
Loading data...
Creating datasets...
16 components selected for the latent vectors
Calling accelerator...
DistributedType.NO
Training starts now...
Model defined
====> Epoch: 0 TRAINING Loss: 4.187e-02  VALIDATION Loss: 4.194e-02
====> Epoch: 1 TRAINING Loss: 4.014e-02  VALIDATION Loss: 3.873e-02
====> Epoch: 2 TRAINING Loss: 3.591e-02  VALIDATION Loss: 3.330e-02
====> Epoch: 3 TRAINING Loss: 2.971e-02  VALIDATION Loss: 2.716e-02
====> Epoch: 4 TRAINING Loss: 2.426e-02  VALIDATION Loss: 2.241e-02
====> Epoch: 5 TRAINING Loss: 2.115e-02  VALIDATION Loss: 2.057e-02
====> Epoch: 6 TRAINING Loss: 1.945e-02  VALIDATION Loss: 1.812e-02
====> Epoch: 7 TRAINING Loss: 1.670e-02  VALIDATION Loss: 1.614e-02
====> Epoch: 8 TRAINING Loss: 1.560e-02  VALIDATION Loss: 1.527e-02
====> Epoch: 9 TRAINING Loss: 1.497e-02  VALIDATION Loss: 1.483e-02
====> Epoch: 10 TRAINING Loss: 1.480e-02  VALIDATION Loss: 1.465e-02
====> Epoch: 11 TRAINING Loss: 1.447e-02  VALIDATION Loss: 1.449e-02
====> Epoch: 12 TRAINING Loss: 1.428e-02  VALIDATION Loss: 1.279e-02
====> Epoch: 13 TRAINING Loss: 8.664e-03  VALIDATION Loss: 7.170e-03
====> Epoch: 14 TRAINING Loss: 7.199e-03  VALIDATION Loss: 7.186e-03
====> Epoch: 15 TRAINING Loss: 7.048e-03  VALIDATION Loss: 7.108e-03
====> Epoch: 16 TRAINING Loss: 7.218e-03  VALIDATION Loss: 7.102e-03
====> Epoch: 17 TRAINING Loss: 7.232e-03  VALIDATION Loss: 7.243e-03
====> Epoch: 18 TRAINING Loss: 7.085e-03  VALIDATION Loss: 7.143e-03
====> Epoch: 19 TRAINING Loss: 7.041e-03  VALIDATION Loss: 7.131e-03
====> Epoch: 20 TRAINING Loss: 7.093e-03  VALIDATION Loss: 7.095e-03
====> Epoch: 21 TRAINING Loss: 6.957e-03  VALIDATION Loss: 6.739e-03
====> Epoch: 22 TRAINING Loss: 6.753e-03  VALIDATION Loss: 6.196e-03
====> Epoch: 23 TRAINING Loss: 6.002e-03  VALIDATION Loss: 6.500e-03
====> Epoch: 24 TRAINING Loss: 6.354e-03  VALIDATION Loss: 5.737e-03
====> Epoch: 25 TRAINING Loss: 5.896e-03  VALIDATION Loss: 5.505e-03
====> Epoch: 26 TRAINING Loss: 5.570e-03  VALIDATION Loss: 5.209e-03
====> Epoch: 27 TRAINING Loss: 5.314e-03  VALIDATION Loss: 5.333e-03
====> Epoch: 28 TRAINING Loss: 5.262e-03  VALIDATION Loss: 5.378e-03
====> Epoch: 29 TRAINING Loss: 5.376e-03  VALIDATION Loss: 4.990e-03
====> Epoch: 30 TRAINING Loss: 5.175e-03  VALIDATION Loss: 5.291e-03
====> Epoch: 31 TRAINING Loss: 5.328e-03  VALIDATION Loss: 5.452e-03
====> Epoch: 32 TRAINING Loss: 4.889e-03  VALIDATION Loss: 4.542e-03
====> Epoch: 33 TRAINING Loss: 5.009e-03  VALIDATION Loss: 4.580e-03
====> Epoch: 34 TRAINING Loss: 4.974e-03  VALIDATION Loss: 5.707e-03
====> Epoch: 35 TRAINING Loss: 5.294e-03  VALIDATION Loss: 4.627e-03
====> Epoch: 36 TRAINING Loss: 5.010e-03  VALIDATION Loss: 5.901e-03
====> Epoch: 37 TRAINING Loss: 4.900e-03  VALIDATION Loss: 4.816e-03
====> Epoch: 38 TRAINING Loss: 4.943e-03  VALIDATION Loss: 4.495e-03
====> Epoch: 39 TRAINING Loss: 5.129e-03  VALIDATION Loss: 4.908e-03
====> Epoch: 40 TRAINING Loss: 4.824e-03  VALIDATION Loss: 4.606e-03
====> Epoch: 41 TRAINING Loss: 4.728e-03  VALIDATION Loss: 5.228e-03
====> Epoch: 42 TRAINING Loss: 5.109e-03  VALIDATION Loss: 4.750e-03
====> Epoch: 43 TRAINING Loss: 4.913e-03  VALIDATION Loss: 5.127e-03
====> Epoch: 44 TRAINING Loss: 4.853e-03  VALIDATION Loss: 5.383e-03
====> Epoch: 45 TRAINING Loss: 5.166e-03  VALIDATION Loss: 5.434e-03
====> Epoch: 46 TRAINING Loss: 4.883e-03  VALIDATION Loss: 5.612e-03
====> Epoch: 47 TRAINING Loss: 4.778e-03  VALIDATION Loss: 4.766e-03
====> Epoch: 48 TRAINING Loss: 4.608e-03  VALIDATION Loss: 4.251e-03
====> Epoch: 49 TRAINING Loss: 4.781e-03  VALIDATION Loss: 5.202e-03
====> Epoch: 50 TRAINING Loss: 4.652e-03  VALIDATION Loss: 4.253e-03
====> Epoch: 51 TRAINING Loss: 4.699e-03  VALIDATION Loss: 4.445e-03
====> Epoch: 52 TRAINING Loss: 4.967e-03  VALIDATION Loss: 4.244e-03
====> Epoch: 53 TRAINING Loss: 4.682e-03  VALIDATION Loss: 4.920e-03
====> Epoch: 54 TRAINING Loss: 4.708e-03  VALIDATION Loss: 4.177e-03
====> Epoch: 55 TRAINING Loss: 4.737e-03  VALIDATION Loss: 4.419e-03
====> Epoch: 56 TRAINING Loss: 4.356e-03  VALIDATION Loss: 5.845e-03
====> Epoch: 57 TRAINING Loss: 4.610e-03  VALIDATION Loss: 4.659e-03
====> Epoch: 58 TRAINING Loss: 4.656e-03  VALIDATION Loss: 4.119e-03
====> Epoch: 59 TRAINING Loss: 4.581e-03  VALIDATION Loss: 5.256e-03
====> Epoch: 60 TRAINING Loss: 4.488e-03  VALIDATION Loss: 4.262e-03
====> Epoch: 61 TRAINING Loss: 4.394e-03  VALIDATION Loss: 4.917e-03
====> Epoch: 62 TRAINING Loss: 4.407e-03  VALIDATION Loss: 4.779e-03
====> Epoch: 63 TRAINING Loss: 4.510e-03  VALIDATION Loss: 4.284e-03
====> Epoch: 64 TRAINING Loss: 4.413e-03  VALIDATION Loss: 3.946e-03
====> Epoch: 65 TRAINING Loss: 4.245e-03  VALIDATION Loss: 4.608e-03
====> Epoch: 66 TRAINING Loss: 4.451e-03  VALIDATION Loss: 4.819e-03
====> Epoch: 67 TRAINING Loss: 4.373e-03  VALIDATION Loss: 3.930e-03
====> Epoch: 68 TRAINING Loss: 4.310e-03  VALIDATION Loss: 4.167e-03
====> Epoch: 69 TRAINING Loss: 4.199e-03  VALIDATION Loss: 4.443e-03
====> Epoch: 70 TRAINING Loss: 4.291e-03  VALIDATION Loss: 3.990e-03
====> Epoch: 71 TRAINING Loss: 4.273e-03  VALIDATION Loss: 4.905e-03
====> Epoch: 72 TRAINING Loss: 4.057e-03  VALIDATION Loss: 4.277e-03
====> Epoch: 73 TRAINING Loss: 4.109e-03  VALIDATION Loss: 3.944e-03
====> Epoch: 74 TRAINING Loss: 4.112e-03  VALIDATION Loss: 6.157e-03
====> Epoch: 75 TRAINING Loss: 4.115e-03  VALIDATION Loss: 4.324e-03
====> Epoch: 76 TRAINING Loss: 4.083e-03  VALIDATION Loss: 3.870e-03
====> Epoch: 77 TRAINING Loss: 3.989e-03  VALIDATION Loss: 4.003e-03
====> Epoch: 78 TRAINING Loss: 4.236e-03  VALIDATION Loss: 4.806e-03
====> Epoch: 79 TRAINING Loss: 3.998e-03  VALIDATION Loss: 4.324e-03
====> Epoch: 80 TRAINING Loss: 3.949e-03  VALIDATION Loss: 5.033e-03
====> Epoch: 81 TRAINING Loss: 3.802e-03  VALIDATION Loss: 4.104e-03
====> Epoch: 82 TRAINING Loss: 3.920e-03  VALIDATION Loss: 3.677e-03
====> Epoch: 83 TRAINING Loss: 3.778e-03  VALIDATION Loss: 4.364e-03
====> Epoch: 84 TRAINING Loss: 3.892e-03  VALIDATION Loss: 3.692e-03
====> Epoch: 85 TRAINING Loss: 3.809e-03  VALIDATION Loss: 4.459e-03
====> Epoch: 86 TRAINING Loss: 3.758e-03  VALIDATION Loss: 4.010e-03
====> Epoch: 87 TRAINING Loss: 3.759e-03  VALIDATION Loss: 3.401e-03
====> Epoch: 88 TRAINING Loss: 3.647e-03  VALIDATION Loss: 3.401e-03
====> Epoch: 89 TRAINING Loss: 3.650e-03  VALIDATION Loss: 3.455e-03
====> Epoch: 90 TRAINING Loss: 3.604e-03  VALIDATION Loss: 3.270e-03
====> Epoch: 91 TRAINING Loss: 3.536e-03  VALIDATION Loss: 3.240e-03
====> Epoch: 92 TRAINING Loss: 3.537e-03  VALIDATION Loss: 4.109e-03
====> Epoch: 93 TRAINING Loss: 3.556e-03  VALIDATION Loss: 3.378e-03
====> Epoch: 94 TRAINING Loss: 3.393e-03  VALIDATION Loss: 3.454e-03
====> Epoch: 95 TRAINING Loss: 3.604e-03  VALIDATION Loss: 3.401e-03
====> Epoch: 96 TRAINING Loss: 3.354e-03  VALIDATION Loss: 3.527e-03
====> Epoch: 97 TRAINING Loss: 3.324e-03  VALIDATION Loss: 3.308e-03
====> Epoch: 98 TRAINING Loss: 3.440e-03  VALIDATION Loss: 3.287e-03
====> Epoch: 99 TRAINING Loss: 3.425e-03  VALIDATION Loss: 3.769e-03
====> Epoch: 100 TRAINING Loss: 3.322e-03  VALIDATION Loss: 3.275e-03
====> Epoch: 101 TRAINING Loss: 3.313e-03  VALIDATION Loss: 3.332e-03
====> Epoch: 102 TRAINING Loss: 3.273e-03  VALIDATION Loss: 3.411e-03
====> Epoch: 103 TRAINING Loss: 3.227e-03  VALIDATION Loss: 3.297e-03
====> Epoch: 104 TRAINING Loss: 3.277e-03  VALIDATION Loss: 3.175e-03
====> Epoch: 105 TRAINING Loss: 3.164e-03  VALIDATION Loss: 3.193e-03
====> Epoch: 106 TRAINING Loss: 3.015e-03  VALIDATION Loss: 3.586e-03
====> Epoch: 107 TRAINING Loss: 3.112e-03  VALIDATION Loss: 3.035e-03
====> Epoch: 108 TRAINING Loss: 3.155e-03  VALIDATION Loss: 2.959e-03
====> Epoch: 109 TRAINING Loss: 3.043e-03  VALIDATION Loss: 3.020e-03
====> Epoch: 110 TRAINING Loss: 3.045e-03  VALIDATION Loss: 3.413e-03
====> Epoch: 111 TRAINING Loss: 2.932e-03  VALIDATION Loss: 2.879e-03
====> Epoch: 112 TRAINING Loss: 2.921e-03  VALIDATION Loss: 3.015e-03
====> Epoch: 113 TRAINING Loss: 2.945e-03  VALIDATION Loss: 2.827e-03
====> Epoch: 114 TRAINING Loss: 2.951e-03  VALIDATION Loss: 2.621e-03
====> Epoch: 115 TRAINING Loss: 2.928e-03  VALIDATION Loss: 2.942e-03
====> Epoch: 116 TRAINING Loss: 2.829e-03  VALIDATION Loss: 2.687e-03
====> Epoch: 117 TRAINING Loss: 2.863e-03  VALIDATION Loss: 3.203e-03
====> Epoch: 118 TRAINING Loss: 2.797e-03  VALIDATION Loss: 2.614e-03
====> Epoch: 119 TRAINING Loss: 2.713e-03  VALIDATION Loss: 2.381e-03
====> Epoch: 120 TRAINING Loss: 2.641e-03  VALIDATION Loss: 3.237e-03
====> Epoch: 121 TRAINING Loss: 2.695e-03  VALIDATION Loss: 2.397e-03
====> Epoch: 122 TRAINING Loss: 2.692e-03  VALIDATION Loss: 2.648e-03
====> Epoch: 123 TRAINING Loss: 2.661e-03  VALIDATION Loss: 3.070e-03
====> Epoch: 124 TRAINING Loss: 2.636e-03  VALIDATION Loss: 2.568e-03
====> Epoch: 125 TRAINING Loss: 2.561e-03  VALIDATION Loss: 2.872e-03
====> Epoch: 126 TRAINING Loss: 2.507e-03  VALIDATION Loss: 2.684e-03
====> Epoch: 127 TRAINING Loss: 2.527e-03  VALIDATION Loss: 2.563e-03
====> Epoch: 128 TRAINING Loss: 2.618e-03  VALIDATION Loss: 2.744e-03
====> Epoch: 129 TRAINING Loss: 2.530e-03  VALIDATION Loss: 2.408e-03
====> Epoch: 130 TRAINING Loss: 2.485e-03  VALIDATION Loss: 2.447e-03
====> Epoch: 131 TRAINING Loss: 2.412e-03  VALIDATION Loss: 2.824e-03
====> Epoch: 132 TRAINING Loss: 2.376e-03  VALIDATION Loss: 2.516e-03
====> Epoch: 133 TRAINING Loss: 2.347e-03  VALIDATION Loss: 2.217e-03
====> Epoch: 134 TRAINING Loss: 2.426e-03  VALIDATION Loss: 2.387e-03
====> Epoch: 135 TRAINING Loss: 2.371e-03  VALIDATION Loss: 2.098e-03
====> Epoch: 136 TRAINING Loss: 2.277e-03  VALIDATION Loss: 2.127e-03
====> Epoch: 137 TRAINING Loss: 2.208e-03  VALIDATION Loss: 2.475e-03
====> Epoch: 138 TRAINING Loss: 2.307e-03  VALIDATION Loss: 2.144e-03
====> Epoch: 139 TRAINING Loss: 2.231e-03  VALIDATION Loss: 2.245e-03
====> Epoch: 140 TRAINING Loss: 2.171e-03  VALIDATION Loss: 2.184e-03
====> Epoch: 141 TRAINING Loss: 2.247e-03  VALIDATION Loss: 2.150e-03
====> Epoch: 142 TRAINING Loss: 2.149e-03  VALIDATION Loss: 2.195e-03
====> Epoch: 143 TRAINING Loss: 2.175e-03  VALIDATION Loss: 2.262e-03
====> Epoch: 144 TRAINING Loss: 2.134e-03  VALIDATION Loss: 2.482e-03
====> Epoch: 145 TRAINING Loss: 2.235e-03  VALIDATION Loss: 2.115e-03
====> Epoch: 146 TRAINING Loss: 2.206e-03  VALIDATION Loss: 2.103e-03
====> Epoch: 147 TRAINING Loss: 2.105e-03  VALIDATION Loss: 1.941e-03
====> Epoch: 148 TRAINING Loss: 2.036e-03  VALIDATION Loss: 2.206e-03
====> Epoch: 149 TRAINING Loss: 1.959e-03  VALIDATION Loss: 1.862e-03
====> Epoch: 150 TRAINING Loss: 2.035e-03  VALIDATION Loss: 2.126e-03
====> Epoch: 151 TRAINING Loss: 2.026e-03  VALIDATION Loss: 2.225e-03
====> Epoch: 152 TRAINING Loss: 1.957e-03  VALIDATION Loss: 2.042e-03
====> Epoch: 153 TRAINING Loss: 2.011e-03  VALIDATION Loss: 1.930e-03
====> Epoch: 154 TRAINING Loss: 1.938e-03  VALIDATION Loss: 1.884e-03
====> Epoch: 155 TRAINING Loss: 1.890e-03  VALIDATION Loss: 2.234e-03
====> Epoch: 156 TRAINING Loss: 1.876e-03  VALIDATION Loss: 1.870e-03
====> Epoch: 157 TRAINING Loss: 2.023e-03  VALIDATION Loss: 2.121e-03
====> Epoch: 158 TRAINING Loss: 1.957e-03  VALIDATION Loss: 1.808e-03
====> Epoch: 159 TRAINING Loss: 1.858e-03  VALIDATION Loss: 2.026e-03
====> Epoch: 160 TRAINING Loss: 1.846e-03  VALIDATION Loss: 2.137e-03
====> Epoch: 161 TRAINING Loss: 1.826e-03  VALIDATION Loss: 1.855e-03
====> Epoch: 162 TRAINING Loss: 1.769e-03  VALIDATION Loss: 1.677e-03
====> Epoch: 163 TRAINING Loss: 1.776e-03  VALIDATION Loss: 1.822e-03
====> Epoch: 164 TRAINING Loss: 1.748e-03  VALIDATION Loss: 1.708e-03
====> Epoch: 165 TRAINING Loss: 1.691e-03  VALIDATION Loss: 1.739e-03
====> Epoch: 166 TRAINING Loss: 1.657e-03  VALIDATION Loss: 1.762e-03
====> Epoch: 167 TRAINING Loss: 1.696e-03  VALIDATION Loss: 1.985e-03
====> Epoch: 168 TRAINING Loss: 1.683e-03  VALIDATION Loss: 1.639e-03
====> Epoch: 169 TRAINING Loss: 1.713e-03  VALIDATION Loss: 1.633e-03
====> Epoch: 170 TRAINING Loss: 1.673e-03  VALIDATION Loss: 1.729e-03
====> Epoch: 171 TRAINING Loss: 1.685e-03  VALIDATION Loss: 1.610e-03
====> Epoch: 172 TRAINING Loss: 1.702e-03  VALIDATION Loss: 1.856e-03
====> Epoch: 173 TRAINING Loss: 1.656e-03  VALIDATION Loss: 1.694e-03
====> Epoch: 174 TRAINING Loss: 1.628e-03  VALIDATION Loss: 1.510e-03
====> Epoch: 175 TRAINING Loss: 1.576e-03  VALIDATION Loss: 1.558e-03
====> Epoch: 176 TRAINING Loss: 1.624e-03  VALIDATION Loss: 1.699e-03
====> Epoch: 177 TRAINING Loss: 1.599e-03  VALIDATION Loss: 1.548e-03
====> Epoch: 178 TRAINING Loss: 1.587e-03  VALIDATION Loss: 1.627e-03
====> Epoch: 179 TRAINING Loss: 1.558e-03  VALIDATION Loss: 1.662e-03
====> Epoch: 180 TRAINING Loss: 1.604e-03  VALIDATION Loss: 1.599e-03
====> Epoch: 181 TRAINING Loss: 1.539e-03  VALIDATION Loss: 1.491e-03
====> Epoch: 182 TRAINING Loss: 1.555e-03  VALIDATION Loss: 1.542e-03
====> Epoch: 183 TRAINING Loss: 1.522e-03  VALIDATION Loss: 1.466e-03
====> Epoch: 184 TRAINING Loss: 1.504e-03  VALIDATION Loss: 1.669e-03
====> Epoch: 185 TRAINING Loss: 1.487e-03  VALIDATION Loss: 1.505e-03
====> Epoch: 186 TRAINING Loss: 1.450e-03  VALIDATION Loss: 1.529e-03
====> Epoch: 187 TRAINING Loss: 1.462e-03  VALIDATION Loss: 1.530e-03
====> Epoch: 188 TRAINING Loss: 1.465e-03  VALIDATION Loss: 1.529e-03
====> Epoch: 189 TRAINING Loss: 1.526e-03  VALIDATION Loss: 1.433e-03
====> Epoch: 190 TRAINING Loss: 1.442e-03  VALIDATION Loss: 1.429e-03
====> Epoch: 191 TRAINING Loss: 1.422e-03  VALIDATION Loss: 1.389e-03
====> Epoch: 192 TRAINING Loss: 1.421e-03  VALIDATION Loss: 1.384e-03
====> Epoch: 193 TRAINING Loss: 1.396e-03  VALIDATION Loss: 1.470e-03
====> Epoch: 194 TRAINING Loss: 1.383e-03  VALIDATION Loss: 1.360e-03
====> Epoch: 195 TRAINING Loss: 1.387e-03  VALIDATION Loss: 1.455e-03
====> Epoch: 196 TRAINING Loss: 1.385e-03  VALIDATION Loss: 1.533e-03
====> Epoch: 197 TRAINING Loss: 1.398e-03  VALIDATION Loss: 1.462e-03
====> Epoch: 198 TRAINING Loss: 1.373e-03  VALIDATION Loss: 1.431e-03
====> Epoch: 199 TRAINING Loss: 1.359e-03  VALIDATION Loss: 1.388e-03
====> Epoch: 200 TRAINING Loss: 1.383e-03  VALIDATION Loss: 1.335e-03
====> Epoch: 201 TRAINING Loss: 1.332e-03  VALIDATION Loss: 1.328e-03
====> Epoch: 202 TRAINING Loss: 1.346e-03  VALIDATION Loss: 1.387e-03
====> Epoch: 203 TRAINING Loss: 1.336e-03  VALIDATION Loss: 1.399e-03
====> Epoch: 204 TRAINING Loss: 1.326e-03  VALIDATION Loss: 1.359e-03
====> Epoch: 205 TRAINING Loss: 1.315e-03  VALIDATION Loss: 1.363e-03
====> Epoch: 206 TRAINING Loss: 1.300e-03  VALIDATION Loss: 1.384e-03
====> Epoch: 207 TRAINING Loss: 1.293e-03  VALIDATION Loss: 1.433e-03
====> Epoch: 208 TRAINING Loss: 1.283e-03  VALIDATION Loss: 1.301e-03
====> Epoch: 209 TRAINING Loss: 1.286e-03  VALIDATION Loss: 1.293e-03
====> Epoch: 210 TRAINING Loss: 1.268e-03  VALIDATION Loss: 1.298e-03
====> Epoch: 211 TRAINING Loss: 1.269e-03  VALIDATION Loss: 1.301e-03
====> Epoch: 212 TRAINING Loss: 1.266e-03  VALIDATION Loss: 1.264e-03
====> Epoch: 213 TRAINING Loss: 1.256e-03  VALIDATION Loss: 1.306e-03
====> Epoch: 214 TRAINING Loss: 1.251e-03  VALIDATION Loss: 1.276e-03
====> Epoch: 215 TRAINING Loss: 1.256e-03  VALIDATION Loss: 1.291e-03
====> Epoch: 216 TRAINING Loss: 1.241e-03  VALIDATION Loss: 1.262e-03
====> Epoch: 217 TRAINING Loss: 1.230e-03  VALIDATION Loss: 1.288e-03
====> Epoch: 218 TRAINING Loss: 1.260e-03  VALIDATION Loss: 1.254e-03
====> Epoch: 219 TRAINING Loss: 1.227e-03  VALIDATION Loss: 1.259e-03
====> Epoch: 220 TRAINING Loss: 1.229e-03  VALIDATION Loss: 1.234e-03
====> Epoch: 221 TRAINING Loss: 1.218e-03  VALIDATION Loss: 1.258e-03
====> Epoch: 222 TRAINING Loss: 1.216e-03  VALIDATION Loss: 1.240e-03
====> Epoch: 223 TRAINING Loss: 1.212e-03  VALIDATION Loss: 1.255e-03
====> Epoch: 224 TRAINING Loss: 1.201e-03  VALIDATION Loss: 1.248e-03
====> Epoch: 225 TRAINING Loss: 1.206e-03  VALIDATION Loss: 1.226e-03
====> Epoch: 226 TRAINING Loss: 1.192e-03  VALIDATION Loss: 1.245e-03
====> Epoch: 227 TRAINING Loss: 1.195e-03  VALIDATION Loss: 1.213e-03
====> Epoch: 228 TRAINING Loss: 1.202e-03  VALIDATION Loss: 1.212e-03
====> Epoch: 229 TRAINING Loss: 1.187e-03  VALIDATION Loss: 1.231e-03
====> Epoch: 230 TRAINING Loss: 1.175e-03  VALIDATION Loss: 1.213e-03
====> Epoch: 231 TRAINING Loss: 1.175e-03  VALIDATION Loss: 1.213e-03
====> Epoch: 232 TRAINING Loss: 1.167e-03  VALIDATION Loss: 1.209e-03
====> Epoch: 233 TRAINING Loss: 1.168e-03  VALIDATION Loss: 1.201e-03
====> Epoch: 234 TRAINING Loss: 1.172e-03  VALIDATION Loss: 1.198e-03
====> Epoch: 235 TRAINING Loss: 1.164e-03  VALIDATION Loss: 1.197e-03
====> Epoch: 236 TRAINING Loss: 1.175e-03  VALIDATION Loss: 1.201e-03
====> Epoch: 237 TRAINING Loss: 1.162e-03  VALIDATION Loss: 1.194e-03
====> Epoch: 238 TRAINING Loss: 1.170e-03  VALIDATION Loss: 1.192e-03
====> Epoch: 239 TRAINING Loss: 1.161e-03  VALIDATION Loss: 1.199e-03
====> Epoch: 240 TRAINING Loss: 1.159e-03  VALIDATION Loss: 1.190e-03
====> Epoch: 241 TRAINING Loss: 1.145e-03  VALIDATION Loss: 1.193e-03
====> Epoch: 242 TRAINING Loss: 1.155e-03  VALIDATION Loss: 1.188e-03
====> Epoch: 243 TRAINING Loss: 1.150e-03  VALIDATION Loss: 1.186e-03
====> Epoch: 244 TRAINING Loss: 1.159e-03  VALIDATION Loss: 1.189e-03
====> Epoch: 245 TRAINING Loss: 1.150e-03  VALIDATION Loss: 1.188e-03
====> Epoch: 246 TRAINING Loss: 1.139e-03  VALIDATION Loss: 1.184e-03
====> Epoch: 247 TRAINING Loss: 1.144e-03  VALIDATION Loss: 1.185e-03
====> Epoch: 248 TRAINING Loss: 1.149e-03  VALIDATION Loss: 1.184e-03
====> Epoch: 249 TRAINING Loss: 1.156e-03  VALIDATION Loss: 1.184e-03
Training has finished
Model saved
n_epochs: 250, batch_size: 128, lr: 5e-04
Modules prepared
cuda:0  prepared
Loading data...
Shuffling...
Dataset prepared
16 components selected for the latent vectors
Shape of the test set:  (15000, 4300)
Calling accelerator...
DistributedType.NO
Loading model...
Testing starts now...
Saving latents and predicted percentiles...
Loading modules
cuda:0  prepared
Loading data...
Creating dataset and calling accelerator
Shape of the dataset:  (150000, 4300)
Loading module trained with latents of  16  components
Getting latent vectors and predicted percentiles
Saving spectra, percentiles, latents and predicted percentiles
