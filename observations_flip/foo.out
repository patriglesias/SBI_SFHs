Starting dense_basis. Failed to load FSPS, only GP-SFH module will be available.
Loading MILES convolved spectra and interpolating in metallicity: 
Generating 10.000 SFHs and their corresponding spectra for each Z:
z=  0
z=  1
z=  2
z=  3
z=  4
z=  5
z=  6
z=  7
z=  8
z=  9
z=  10
z=  11
z=  12
z=  13
z=  14
Reshaping...
Saving...
Modules prepared
GPU  prepared
Loading data...
Creating datasets...
16 components selected for the latent vectors
Calling accelerator...
DistributedType.NO
Training starts now...
Model defined
====> Epoch: 0 TRAINING Loss: 3.185e-02  VALIDATION Loss: 3.166e-02
====> Epoch: 1 TRAINING Loss: 3.051e-02  VALIDATION Loss: 2.968e-02
====> Epoch: 2 TRAINING Loss: 2.772e-02  VALIDATION Loss: 2.576e-02
====> Epoch: 3 TRAINING Loss: 2.376e-02  VALIDATION Loss: 2.209e-02
====> Epoch: 4 TRAINING Loss: 1.950e-02  VALIDATION Loss: 1.721e-02
====> Epoch: 5 TRAINING Loss: 1.519e-02  VALIDATION Loss: 1.326e-02
====> Epoch: 6 TRAINING Loss: 9.359e-03  VALIDATION Loss: 5.983e-03
====> Epoch: 7 TRAINING Loss: 5.112e-03  VALIDATION Loss: 4.791e-03
====> Epoch: 8 TRAINING Loss: 4.766e-03  VALIDATION Loss: 4.806e-03
====> Epoch: 9 TRAINING Loss: 4.674e-03  VALIDATION Loss: 4.679e-03
====> Epoch: 10 TRAINING Loss: 4.535e-03  VALIDATION Loss: 4.494e-03
====> Epoch: 11 TRAINING Loss: 4.374e-03  VALIDATION Loss: 4.261e-03
====> Epoch: 12 TRAINING Loss: 4.156e-03  VALIDATION Loss: 4.116e-03
====> Epoch: 13 TRAINING Loss: 3.928e-03  VALIDATION Loss: 3.846e-03
====> Epoch: 14 TRAINING Loss: 3.766e-03  VALIDATION Loss: 3.676e-03
====> Epoch: 15 TRAINING Loss: 3.564e-03  VALIDATION Loss: 3.560e-03
====> Epoch: 16 TRAINING Loss: 3.428e-03  VALIDATION Loss: 3.360e-03
====> Epoch: 17 TRAINING Loss: 3.327e-03  VALIDATION Loss: 3.246e-03
====> Epoch: 18 TRAINING Loss: 3.226e-03  VALIDATION Loss: 3.221e-03
====> Epoch: 19 TRAINING Loss: 3.241e-03  VALIDATION Loss: 3.227e-03
====> Epoch: 20 TRAINING Loss: 3.217e-03  VALIDATION Loss: 3.167e-03
====> Epoch: 21 TRAINING Loss: 3.220e-03  VALIDATION Loss: 3.174e-03
====> Epoch: 22 TRAINING Loss: 3.153e-03  VALIDATION Loss: 3.146e-03
====> Epoch: 23 TRAINING Loss: 3.232e-03  VALIDATION Loss: 3.134e-03
====> Epoch: 24 TRAINING Loss: 3.179e-03  VALIDATION Loss: 3.374e-03
====> Epoch: 25 TRAINING Loss: 3.141e-03  VALIDATION Loss: 3.165e-03
====> Epoch: 26 TRAINING Loss: 3.125e-03  VALIDATION Loss: 3.079e-03
====> Epoch: 27 TRAINING Loss: 3.156e-03  VALIDATION Loss: 3.082e-03
====> Epoch: 28 TRAINING Loss: 3.145e-03  VALIDATION Loss: 3.130e-03
====> Epoch: 29 TRAINING Loss: 3.065e-03  VALIDATION Loss: 3.052e-03
====> Epoch: 30 TRAINING Loss: 3.115e-03  VALIDATION Loss: 3.102e-03
====> Epoch: 31 TRAINING Loss: 3.140e-03  VALIDATION Loss: 3.136e-03
====> Epoch: 32 TRAINING Loss: 3.044e-03  VALIDATION Loss: 3.177e-03
====> Epoch: 33 TRAINING Loss: 3.051e-03  VALIDATION Loss: 3.054e-03
====> Epoch: 34 TRAINING Loss: 3.053e-03  VALIDATION Loss: 2.991e-03
====> Epoch: 35 TRAINING Loss: 3.042e-03  VALIDATION Loss: 3.016e-03
====> Epoch: 36 TRAINING Loss: 3.034e-03  VALIDATION Loss: 3.042e-03
====> Epoch: 37 TRAINING Loss: 2.987e-03  VALIDATION Loss: 3.058e-03
====> Epoch: 38 TRAINING Loss: 2.973e-03  VALIDATION Loss: 2.966e-03
====> Epoch: 39 TRAINING Loss: 2.983e-03  VALIDATION Loss: 3.001e-03
====> Epoch: 40 TRAINING Loss: 2.952e-03  VALIDATION Loss: 2.882e-03
====> Epoch: 41 TRAINING Loss: 2.936e-03  VALIDATION Loss: 3.074e-03
====> Epoch: 42 TRAINING Loss: 2.985e-03  VALIDATION Loss: 3.114e-03
====> Epoch: 43 TRAINING Loss: 2.926e-03  VALIDATION Loss: 3.168e-03
====> Epoch: 44 TRAINING Loss: 2.955e-03  VALIDATION Loss: 2.998e-03
====> Epoch: 45 TRAINING Loss: 2.877e-03  VALIDATION Loss: 2.962e-03
====> Epoch: 46 TRAINING Loss: 2.920e-03  VALIDATION Loss: 2.863e-03
====> Epoch: 47 TRAINING Loss: 2.897e-03  VALIDATION Loss: 2.843e-03
====> Epoch: 48 TRAINING Loss: 2.902e-03  VALIDATION Loss: 2.907e-03
====> Epoch: 49 TRAINING Loss: 2.880e-03  VALIDATION Loss: 2.826e-03
====> Epoch: 50 TRAINING Loss: 2.888e-03  VALIDATION Loss: 2.885e-03
====> Epoch: 51 TRAINING Loss: 2.816e-03  VALIDATION Loss: 2.831e-03
====> Epoch: 52 TRAINING Loss: 2.856e-03  VALIDATION Loss: 2.779e-03
====> Epoch: 53 TRAINING Loss: 2.798e-03  VALIDATION Loss: 2.759e-03
====> Epoch: 54 TRAINING Loss: 2.883e-03  VALIDATION Loss: 2.787e-03
====> Epoch: 55 TRAINING Loss: 2.834e-03  VALIDATION Loss: 2.781e-03
====> Epoch: 56 TRAINING Loss: 2.860e-03  VALIDATION Loss: 2.819e-03
====> Epoch: 57 TRAINING Loss: 2.826e-03  VALIDATION Loss: 2.901e-03
====> Epoch: 58 TRAINING Loss: 2.788e-03  VALIDATION Loss: 2.727e-03
====> Epoch: 59 TRAINING Loss: 2.816e-03  VALIDATION Loss: 2.746e-03
====> Epoch: 60 TRAINING Loss: 2.781e-03  VALIDATION Loss: 2.849e-03
====> Epoch: 61 TRAINING Loss: 2.784e-03  VALIDATION Loss: 2.894e-03
====> Epoch: 62 TRAINING Loss: 2.774e-03  VALIDATION Loss: 2.764e-03
====> Epoch: 63 TRAINING Loss: 2.726e-03  VALIDATION Loss: 2.775e-03
====> Epoch: 64 TRAINING Loss: 2.746e-03  VALIDATION Loss: 2.726e-03
====> Epoch: 65 TRAINING Loss: 2.736e-03  VALIDATION Loss: 2.663e-03
====> Epoch: 66 TRAINING Loss: 2.707e-03  VALIDATION Loss: 2.729e-03
====> Epoch: 67 TRAINING Loss: 2.708e-03  VALIDATION Loss: 2.687e-03
====> Epoch: 68 TRAINING Loss: 2.692e-03  VALIDATION Loss: 2.815e-03
====> Epoch: 69 TRAINING Loss: 2.726e-03  VALIDATION Loss: 2.715e-03
====> Epoch: 70 TRAINING Loss: 2.697e-03  VALIDATION Loss: 2.886e-03
====> Epoch: 71 TRAINING Loss: 2.672e-03  VALIDATION Loss: 2.591e-03
====> Epoch: 72 TRAINING Loss: 2.696e-03  VALIDATION Loss: 2.647e-03
====> Epoch: 73 TRAINING Loss: 2.623e-03  VALIDATION Loss: 2.614e-03
====> Epoch: 74 TRAINING Loss: 2.623e-03  VALIDATION Loss: 2.558e-03
====> Epoch: 75 TRAINING Loss: 2.642e-03  VALIDATION Loss: 2.603e-03
====> Epoch: 76 TRAINING Loss: 2.667e-03  VALIDATION Loss: 2.579e-03
====> Epoch: 77 TRAINING Loss: 2.628e-03  VALIDATION Loss: 2.615e-03
====> Epoch: 78 TRAINING Loss: 2.598e-03  VALIDATION Loss: 2.591e-03
====> Epoch: 79 TRAINING Loss: 2.627e-03  VALIDATION Loss: 2.507e-03
====> Epoch: 80 TRAINING Loss: 2.614e-03  VALIDATION Loss: 2.515e-03
====> Epoch: 81 TRAINING Loss: 2.541e-03  VALIDATION Loss: 2.512e-03
====> Epoch: 82 TRAINING Loss: 2.545e-03  VALIDATION Loss: 2.429e-03
====> Epoch: 83 TRAINING Loss: 2.565e-03  VALIDATION Loss: 2.552e-03
====> Epoch: 84 TRAINING Loss: 2.581e-03  VALIDATION Loss: 2.539e-03
====> Epoch: 85 TRAINING Loss: 2.592e-03  VALIDATION Loss: 2.628e-03
====> Epoch: 86 TRAINING Loss: 2.530e-03  VALIDATION Loss: 2.587e-03
====> Epoch: 87 TRAINING Loss: 2.557e-03  VALIDATION Loss: 2.498e-03
====> Epoch: 88 TRAINING Loss: 2.509e-03  VALIDATION Loss: 2.372e-03
====> Epoch: 89 TRAINING Loss: 2.494e-03  VALIDATION Loss: 2.458e-03
====> Epoch: 90 TRAINING Loss: 2.456e-03  VALIDATION Loss: 2.385e-03
====> Epoch: 91 TRAINING Loss: 2.379e-03  VALIDATION Loss: 2.726e-03
====> Epoch: 92 TRAINING Loss: 2.409e-03  VALIDATION Loss: 2.336e-03
====> Epoch: 93 TRAINING Loss: 2.436e-03  VALIDATION Loss: 2.488e-03
====> Epoch: 94 TRAINING Loss: 2.373e-03  VALIDATION Loss: 2.892e-03
====> Epoch: 95 TRAINING Loss: 2.402e-03  VALIDATION Loss: 2.538e-03
====> Epoch: 96 TRAINING Loss: 2.379e-03  VALIDATION Loss: 2.457e-03
====> Epoch: 97 TRAINING Loss: 2.318e-03  VALIDATION Loss: 2.484e-03
====> Epoch: 98 TRAINING Loss: 2.399e-03  VALIDATION Loss: 2.539e-03
====> Epoch: 99 TRAINING Loss: 2.374e-03  VALIDATION Loss: 2.273e-03
====> Epoch: 100 TRAINING Loss: 2.329e-03  VALIDATION Loss: 2.278e-03
====> Epoch: 101 TRAINING Loss: 2.290e-03  VALIDATION Loss: 2.296e-03
====> Epoch: 102 TRAINING Loss: 2.281e-03  VALIDATION Loss: 2.306e-03
====> Epoch: 103 TRAINING Loss: 2.298e-03  VALIDATION Loss: 2.150e-03
====> Epoch: 104 TRAINING Loss: 2.238e-03  VALIDATION Loss: 2.732e-03
====> Epoch: 105 TRAINING Loss: 2.264e-03  VALIDATION Loss: 2.471e-03
====> Epoch: 106 TRAINING Loss: 2.235e-03  VALIDATION Loss: 2.292e-03
====> Epoch: 107 TRAINING Loss: 2.199e-03  VALIDATION Loss: 2.227e-03
====> Epoch: 108 TRAINING Loss: 2.178e-03  VALIDATION Loss: 2.190e-03
====> Epoch: 109 TRAINING Loss: 2.223e-03  VALIDATION Loss: 2.208e-03
====> Epoch: 110 TRAINING Loss: 2.208e-03  VALIDATION Loss: 2.124e-03
====> Epoch: 111 TRAINING Loss: 2.169e-03  VALIDATION Loss: 2.551e-03
====> Epoch: 112 TRAINING Loss: 2.165e-03  VALIDATION Loss: 2.110e-03
====> Epoch: 113 TRAINING Loss: 2.101e-03  VALIDATION Loss: 2.155e-03
====> Epoch: 114 TRAINING Loss: 2.129e-03  VALIDATION Loss: 2.066e-03
====> Epoch: 115 TRAINING Loss: 2.219e-03  VALIDATION Loss: 2.262e-03
====> Epoch: 116 TRAINING Loss: 2.149e-03  VALIDATION Loss: 2.080e-03
====> Epoch: 117 TRAINING Loss: 2.067e-03  VALIDATION Loss: 2.008e-03
====> Epoch: 118 TRAINING Loss: 2.152e-03  VALIDATION Loss: 2.653e-03
====> Epoch: 119 TRAINING Loss: 2.100e-03  VALIDATION Loss: 3.099e-03
====> Epoch: 120 TRAINING Loss: 2.099e-03  VALIDATION Loss: 2.012e-03
====> Epoch: 121 TRAINING Loss: 2.070e-03  VALIDATION Loss: 2.097e-03
====> Epoch: 122 TRAINING Loss: 2.051e-03  VALIDATION Loss: 2.031e-03
====> Epoch: 123 TRAINING Loss: 2.057e-03  VALIDATION Loss: 1.972e-03
====> Epoch: 124 TRAINING Loss: 2.071e-03  VALIDATION Loss: 2.115e-03
====> Epoch: 125 TRAINING Loss: 2.079e-03  VALIDATION Loss: 1.968e-03
====> Epoch: 126 TRAINING Loss: 2.052e-03  VALIDATION Loss: 2.026e-03
====> Epoch: 127 TRAINING Loss: 2.076e-03  VALIDATION Loss: 2.039e-03
====> Epoch: 128 TRAINING Loss: 1.966e-03  VALIDATION Loss: 1.963e-03
====> Epoch: 129 TRAINING Loss: 2.007e-03  VALIDATION Loss: 1.944e-03
====> Epoch: 130 TRAINING Loss: 2.028e-03  VALIDATION Loss: 2.011e-03
====> Epoch: 131 TRAINING Loss: 2.001e-03  VALIDATION Loss: 1.959e-03
====> Epoch: 132 TRAINING Loss: 1.983e-03  VALIDATION Loss: 2.251e-03
====> Epoch: 133 TRAINING Loss: 2.029e-03  VALIDATION Loss: 1.921e-03
====> Epoch: 134 TRAINING Loss: 1.995e-03  VALIDATION Loss: 2.012e-03
====> Epoch: 135 TRAINING Loss: 1.970e-03  VALIDATION Loss: 1.978e-03
====> Epoch: 136 TRAINING Loss: 1.965e-03  VALIDATION Loss: 1.964e-03
====> Epoch: 137 TRAINING Loss: 1.986e-03  VALIDATION Loss: 1.950e-03
====> Epoch: 138 TRAINING Loss: 1.962e-03  VALIDATION Loss: 1.980e-03
====> Epoch: 139 TRAINING Loss: 1.956e-03  VALIDATION Loss: 1.924e-03
====> Epoch: 140 TRAINING Loss: 1.923e-03  VALIDATION Loss: 1.882e-03
====> Epoch: 141 TRAINING Loss: 1.966e-03  VALIDATION Loss: 1.945e-03
====> Epoch: 142 TRAINING Loss: 1.924e-03  VALIDATION Loss: 2.056e-03
====> Epoch: 143 TRAINING Loss: 1.950e-03  VALIDATION Loss: 1.931e-03
====> Epoch: 144 TRAINING Loss: 1.944e-03  VALIDATION Loss: 1.938e-03
====> Epoch: 145 TRAINING Loss: 1.909e-03  VALIDATION Loss: 1.844e-03
====> Epoch: 146 TRAINING Loss: 1.885e-03  VALIDATION Loss: 1.881e-03
====> Epoch: 147 TRAINING Loss: 1.889e-03  VALIDATION Loss: 1.978e-03
====> Epoch: 148 TRAINING Loss: 1.903e-03  VALIDATION Loss: 1.884e-03
====> Epoch: 149 TRAINING Loss: 1.880e-03  VALIDATION Loss: 1.925e-03
====> Epoch: 150 TRAINING Loss: 1.927e-03  VALIDATION Loss: 1.840e-03
====> Epoch: 151 TRAINING Loss: 1.878e-03  VALIDATION Loss: 1.839e-03
====> Epoch: 152 TRAINING Loss: 1.915e-03  VALIDATION Loss: 1.966e-03
====> Epoch: 153 TRAINING Loss: 1.923e-03  VALIDATION Loss: 2.015e-03
====> Epoch: 154 TRAINING Loss: 1.890e-03  VALIDATION Loss: 1.853e-03
====> Epoch: 155 TRAINING Loss: 1.958e-03  VALIDATION Loss: 1.848e-03
====> Epoch: 156 TRAINING Loss: 1.853e-03  VALIDATION Loss: 1.900e-03
====> Epoch: 157 TRAINING Loss: 1.896e-03  VALIDATION Loss: 1.860e-03
====> Epoch: 158 TRAINING Loss: 1.871e-03  VALIDATION Loss: 1.836e-03
====> Epoch: 159 TRAINING Loss: 1.823e-03  VALIDATION Loss: 1.843e-03
====> Epoch: 160 TRAINING Loss: 1.837e-03  VALIDATION Loss: 1.812e-03
====> Epoch: 161 TRAINING Loss: 1.850e-03  VALIDATION Loss: 1.805e-03
====> Epoch: 162 TRAINING Loss: 1.863e-03  VALIDATION Loss: 1.874e-03
====> Epoch: 163 TRAINING Loss: 1.832e-03  VALIDATION Loss: 1.894e-03
====> Epoch: 164 TRAINING Loss: 1.830e-03  VALIDATION Loss: 1.832e-03
====> Epoch: 165 TRAINING Loss: 1.812e-03  VALIDATION Loss: 1.843e-03
====> Epoch: 166 TRAINING Loss: 1.811e-03  VALIDATION Loss: 1.864e-03
====> Epoch: 167 TRAINING Loss: 1.815e-03  VALIDATION Loss: 1.869e-03
====> Epoch: 168 TRAINING Loss: 1.817e-03  VALIDATION Loss: 1.837e-03
====> Epoch: 169 TRAINING Loss: 1.844e-03  VALIDATION Loss: 1.766e-03
====> Epoch: 170 TRAINING Loss: 1.809e-03  VALIDATION Loss: 1.816e-03
====> Epoch: 171 TRAINING Loss: 1.777e-03  VALIDATION Loss: 1.779e-03
====> Epoch: 172 TRAINING Loss: 1.782e-03  VALIDATION Loss: 1.761e-03
====> Epoch: 173 TRAINING Loss: 1.770e-03  VALIDATION Loss: 1.772e-03
====> Epoch: 174 TRAINING Loss: 1.799e-03  VALIDATION Loss: 1.831e-03
====> Epoch: 175 TRAINING Loss: 1.790e-03  VALIDATION Loss: 1.746e-03
====> Epoch: 176 TRAINING Loss: 1.777e-03  VALIDATION Loss: 1.769e-03
====> Epoch: 177 TRAINING Loss: 1.742e-03  VALIDATION Loss: 1.853e-03
====> Epoch: 178 TRAINING Loss: 1.769e-03  VALIDATION Loss: 1.839e-03
====> Epoch: 179 TRAINING Loss: 1.772e-03  VALIDATION Loss: 1.819e-03
====> Epoch: 180 TRAINING Loss: 1.779e-03  VALIDATION Loss: 1.789e-03
====> Epoch: 181 TRAINING Loss: 1.751e-03  VALIDATION Loss: 1.799e-03
====> Epoch: 182 TRAINING Loss: 1.753e-03  VALIDATION Loss: 1.853e-03
====> Epoch: 183 TRAINING Loss: 1.817e-03  VALIDATION Loss: 1.730e-03
====> Epoch: 184 TRAINING Loss: 1.754e-03  VALIDATION Loss: 1.737e-03
====> Epoch: 185 TRAINING Loss: 1.751e-03  VALIDATION Loss: 1.840e-03
====> Epoch: 186 TRAINING Loss: 1.727e-03  VALIDATION Loss: 1.776e-03
====> Epoch: 187 TRAINING Loss: 1.747e-03  VALIDATION Loss: 1.726e-03
====> Epoch: 188 TRAINING Loss: 1.722e-03  VALIDATION Loss: 1.771e-03
====> Epoch: 189 TRAINING Loss: 1.721e-03  VALIDATION Loss: 1.743e-03
====> Epoch: 190 TRAINING Loss: 1.735e-03  VALIDATION Loss: 1.794e-03
====> Epoch: 191 TRAINING Loss: 1.708e-03  VALIDATION Loss: 1.704e-03
====> Epoch: 192 TRAINING Loss: 1.710e-03  VALIDATION Loss: 1.701e-03
====> Epoch: 193 TRAINING Loss: 1.735e-03  VALIDATION Loss: 1.705e-03
====> Epoch: 194 TRAINING Loss: 1.730e-03  VALIDATION Loss: 1.776e-03
====> Epoch: 195 TRAINING Loss: 1.707e-03  VALIDATION Loss: 1.720e-03
====> Epoch: 196 TRAINING Loss: 1.695e-03  VALIDATION Loss: 1.711e-03
====> Epoch: 197 TRAINING Loss: 1.704e-03  VALIDATION Loss: 1.716e-03
====> Epoch: 198 TRAINING Loss: 1.715e-03  VALIDATION Loss: 1.712e-03
====> Epoch: 199 TRAINING Loss: 1.697e-03  VALIDATION Loss: 1.699e-03
====> Epoch: 200 TRAINING Loss: 1.667e-03  VALIDATION Loss: 1.703e-03
====> Epoch: 201 TRAINING Loss: 1.718e-03  VALIDATION Loss: 1.766e-03
====> Epoch: 202 TRAINING Loss: 1.699e-03  VALIDATION Loss: 1.739e-03
====> Epoch: 203 TRAINING Loss: 1.677e-03  VALIDATION Loss: 1.706e-03
====> Epoch: 204 TRAINING Loss: 1.675e-03  VALIDATION Loss: 1.678e-03
====> Epoch: 205 TRAINING Loss: 1.655e-03  VALIDATION Loss: 1.681e-03
====> Epoch: 206 TRAINING Loss: 1.658e-03  VALIDATION Loss: 1.671e-03
====> Epoch: 207 TRAINING Loss: 1.676e-03  VALIDATION Loss: 1.715e-03
====> Epoch: 208 TRAINING Loss: 1.672e-03  VALIDATION Loss: 1.682e-03
====> Epoch: 209 TRAINING Loss: 1.666e-03  VALIDATION Loss: 1.688e-03
====> Epoch: 210 TRAINING Loss: 1.649e-03  VALIDATION Loss: 1.664e-03
====> Epoch: 211 TRAINING Loss: 1.677e-03  VALIDATION Loss: 1.742e-03
====> Epoch: 212 TRAINING Loss: 1.675e-03  VALIDATION Loss: 1.663e-03
====> Epoch: 213 TRAINING Loss: 1.652e-03  VALIDATION Loss: 1.691e-03
====> Epoch: 214 TRAINING Loss: 1.678e-03  VALIDATION Loss: 1.671e-03
====> Epoch: 215 TRAINING Loss: 1.654e-03  VALIDATION Loss: 1.660e-03
====> Epoch: 216 TRAINING Loss: 1.670e-03  VALIDATION Loss: 1.656e-03
====> Epoch: 217 TRAINING Loss: 1.648e-03  VALIDATION Loss: 1.654e-03
====> Epoch: 218 TRAINING Loss: 1.642e-03  VALIDATION Loss: 1.663e-03
====> Epoch: 219 TRAINING Loss: 1.646e-03  VALIDATION Loss: 1.648e-03
====> Epoch: 220 TRAINING Loss: 1.644e-03  VALIDATION Loss: 1.650e-03
====> Epoch: 221 TRAINING Loss: 1.639e-03  VALIDATION Loss: 1.652e-03
====> Epoch: 222 TRAINING Loss: 1.631e-03  VALIDATION Loss: 1.645e-03
====> Epoch: 223 TRAINING Loss: 1.621e-03  VALIDATION Loss: 1.655e-03
====> Epoch: 224 TRAINING Loss: 1.616e-03  VALIDATION Loss: 1.643e-03
====> Epoch: 225 TRAINING Loss: 1.621e-03  VALIDATION Loss: 1.640e-03
====> Epoch: 226 TRAINING Loss: 1.635e-03  VALIDATION Loss: 1.645e-03
====> Epoch: 227 TRAINING Loss: 1.627e-03  VALIDATION Loss: 1.634e-03
====> Epoch: 228 TRAINING Loss: 1.631e-03  VALIDATION Loss: 1.642e-03
====> Epoch: 229 TRAINING Loss: 1.617e-03  VALIDATION Loss: 1.637e-03
====> Epoch: 230 TRAINING Loss: 1.630e-03  VALIDATION Loss: 1.629e-03
====> Epoch: 231 TRAINING Loss: 1.621e-03  VALIDATION Loss: 1.635e-03
====> Epoch: 232 TRAINING Loss: 1.612e-03  VALIDATION Loss: 1.637e-03
====> Epoch: 233 TRAINING Loss: 1.611e-03  VALIDATION Loss: 1.624e-03
====> Epoch: 234 TRAINING Loss: 1.619e-03  VALIDATION Loss: 1.625e-03
====> Epoch: 235 TRAINING Loss: 1.605e-03  VALIDATION Loss: 1.633e-03
====> Epoch: 236 TRAINING Loss: 1.619e-03  VALIDATION Loss: 1.625e-03
====> Epoch: 237 TRAINING Loss: 1.616e-03  VALIDATION Loss: 1.622e-03
====> Epoch: 238 TRAINING Loss: 1.621e-03  VALIDATION Loss: 1.623e-03
====> Epoch: 239 TRAINING Loss: 1.602e-03  VALIDATION Loss: 1.620e-03
====> Epoch: 240 TRAINING Loss: 1.610e-03  VALIDATION Loss: 1.621e-03
====> Epoch: 241 TRAINING Loss: 1.608e-03  VALIDATION Loss: 1.618e-03
====> Epoch: 242 TRAINING Loss: 1.594e-03  VALIDATION Loss: 1.623e-03
====> Epoch: 243 TRAINING Loss: 1.607e-03  VALIDATION Loss: 1.618e-03
====> Epoch: 244 TRAINING Loss: 1.605e-03  VALIDATION Loss: 1.619e-03
====> Epoch: 245 TRAINING Loss: 1.601e-03  VALIDATION Loss: 1.618e-03
====> Epoch: 246 TRAINING Loss: 1.613e-03  VALIDATION Loss: 1.616e-03
====> Epoch: 247 TRAINING Loss: 1.589e-03  VALIDATION Loss: 1.618e-03
====> Epoch: 248 TRAINING Loss: 1.591e-03  VALIDATION Loss: 1.617e-03
====> Epoch: 249 TRAINING Loss: 1.613e-03  VALIDATION Loss: 1.617e-03
Training has finished
Model saved
n_epochs: 250, batch_size: 128, lr: 5e-04
Modules prepared
cuda:0  prepared
Loading data...
Shuffling...
Dataset prepared
16 components selected for the latent vectors
Shape of the test set:  (15000, 1978)
Calling accelerator...
DistributedType.NO
Loading model...
Testing starts now...
Saving latents and predicted percentiles...
Loading modules
cuda:0  prepared
Loading data...
Creating dataset and calling accelerator
Shape of the dataset:  (150000, 1978)
Loading module trained with latents of  16  components
Getting latent vectors and predicted percentiles
Saving spectra, percentiles, latents and predicted percentiles
