Starting dense_basis. Failed to load FSPS, only GP-SFH module will be available.
Loading MILES convolved spectra and interpolating in metallicity: 
Generating 10.000 SFHs and their corresponding spectra for each Z:
z=  0
z=  1
z=  2
z=  3
z=  4
z=  5
z=  6
z=  7
z=  8
z=  9
z=  10
z=  11
z=  12
z=  13
z=  14
Reshaping...
Saving...
Modules prepared
GPU  prepared
Loading data...
Creating datasets...
16 components selected for the latent vectors
Calling accelerator...
DistributedType.NO
Training starts now...
Model defined
====> Epoch: 0 TRAINING Loss: 4.211e-02  VALIDATION Loss: 4.165e-02
====> Epoch: 1 TRAINING Loss: 3.909e-02  VALIDATION Loss: 3.595e-02
====> Epoch: 2 TRAINING Loss: 2.845e-02  VALIDATION Loss: 1.927e-02
====> Epoch: 3 TRAINING Loss: 1.340e-02  VALIDATION Loss: 1.055e-02
====> Epoch: 4 TRAINING Loss: 8.402e-03  VALIDATION Loss: 6.589e-03
====> Epoch: 5 TRAINING Loss: 5.328e-03  VALIDATION Loss: 4.520e-03
====> Epoch: 6 TRAINING Loss: 4.193e-03  VALIDATION Loss: 4.075e-03
====> Epoch: 7 TRAINING Loss: 4.034e-03  VALIDATION Loss: 4.031e-03
====> Epoch: 8 TRAINING Loss: 4.012e-03  VALIDATION Loss: 4.022e-03
====> Epoch: 9 TRAINING Loss: 3.955e-03  VALIDATION Loss: 3.791e-03
====> Epoch: 10 TRAINING Loss: 3.235e-03  VALIDATION Loss: 3.150e-03
====> Epoch: 11 TRAINING Loss: 3.103e-03  VALIDATION Loss: 3.158e-03
====> Epoch: 12 TRAINING Loss: 3.124e-03  VALIDATION Loss: 3.205e-03
====> Epoch: 13 TRAINING Loss: 3.103e-03  VALIDATION Loss: 3.129e-03
====> Epoch: 14 TRAINING Loss: 3.095e-03  VALIDATION Loss: 3.123e-03
====> Epoch: 15 TRAINING Loss: 3.125e-03  VALIDATION Loss: 3.285e-03
====> Epoch: 16 TRAINING Loss: 3.107e-03  VALIDATION Loss: 3.126e-03
====> Epoch: 17 TRAINING Loss: 3.096e-03  VALIDATION Loss: 3.096e-03
====> Epoch: 18 TRAINING Loss: 3.098e-03  VALIDATION Loss: 3.103e-03
====> Epoch: 19 TRAINING Loss: 3.065e-03  VALIDATION Loss: 3.089e-03
====> Epoch: 20 TRAINING Loss: 3.053e-03  VALIDATION Loss: 3.078e-03
====> Epoch: 21 TRAINING Loss: 3.041e-03  VALIDATION Loss: 3.047e-03
====> Epoch: 22 TRAINING Loss: 3.104e-03  VALIDATION Loss: 3.051e-03
====> Epoch: 23 TRAINING Loss: 3.049e-03  VALIDATION Loss: 3.076e-03
====> Epoch: 24 TRAINING Loss: 3.035e-03  VALIDATION Loss: 3.112e-03
====> Epoch: 25 TRAINING Loss: 3.070e-03  VALIDATION Loss: 3.014e-03
====> Epoch: 26 TRAINING Loss: 3.010e-03  VALIDATION Loss: 3.030e-03
====> Epoch: 27 TRAINING Loss: 2.964e-03  VALIDATION Loss: 2.969e-03
====> Epoch: 28 TRAINING Loss: 2.987e-03  VALIDATION Loss: 3.017e-03
====> Epoch: 29 TRAINING Loss: 2.947e-03  VALIDATION Loss: 2.992e-03
====> Epoch: 30 TRAINING Loss: 2.965e-03  VALIDATION Loss: 2.956e-03
====> Epoch: 31 TRAINING Loss: 2.909e-03  VALIDATION Loss: 2.874e-03
====> Epoch: 32 TRAINING Loss: 2.912e-03  VALIDATION Loss: 2.884e-03
====> Epoch: 33 TRAINING Loss: 2.855e-03  VALIDATION Loss: 2.899e-03
====> Epoch: 34 TRAINING Loss: 2.790e-03  VALIDATION Loss: 2.729e-03
====> Epoch: 35 TRAINING Loss: 2.744e-03  VALIDATION Loss: 2.750e-03
====> Epoch: 36 TRAINING Loss: 2.714e-03  VALIDATION Loss: 2.824e-03
====> Epoch: 37 TRAINING Loss: 2.681e-03  VALIDATION Loss: 2.724e-03
====> Epoch: 38 TRAINING Loss: 2.673e-03  VALIDATION Loss: 2.756e-03
====> Epoch: 39 TRAINING Loss: 2.678e-03  VALIDATION Loss: 2.690e-03
====> Epoch: 40 TRAINING Loss: 2.654e-03  VALIDATION Loss: 2.666e-03
====> Epoch: 41 TRAINING Loss: 2.631e-03  VALIDATION Loss: 2.605e-03
====> Epoch: 42 TRAINING Loss: 2.638e-03  VALIDATION Loss: 2.580e-03
====> Epoch: 43 TRAINING Loss: 2.590e-03  VALIDATION Loss: 2.631e-03
====> Epoch: 44 TRAINING Loss: 2.621e-03  VALIDATION Loss: 2.630e-03
====> Epoch: 45 TRAINING Loss: 2.622e-03  VALIDATION Loss: 2.849e-03
====> Epoch: 46 TRAINING Loss: 2.603e-03  VALIDATION Loss: 2.559e-03
====> Epoch: 47 TRAINING Loss: 2.654e-03  VALIDATION Loss: 2.786e-03
====> Epoch: 48 TRAINING Loss: 2.644e-03  VALIDATION Loss: 2.636e-03
====> Epoch: 49 TRAINING Loss: 2.614e-03  VALIDATION Loss: 2.513e-03
====> Epoch: 50 TRAINING Loss: 2.565e-03  VALIDATION Loss: 2.518e-03
====> Epoch: 51 TRAINING Loss: 2.531e-03  VALIDATION Loss: 2.570e-03
====> Epoch: 52 TRAINING Loss: 2.612e-03  VALIDATION Loss: 2.520e-03
====> Epoch: 53 TRAINING Loss: 2.492e-03  VALIDATION Loss: 2.563e-03
====> Epoch: 54 TRAINING Loss: 2.539e-03  VALIDATION Loss: 2.467e-03
====> Epoch: 55 TRAINING Loss: 2.506e-03  VALIDATION Loss: 2.478e-03
====> Epoch: 56 TRAINING Loss: 2.491e-03  VALIDATION Loss: 2.662e-03
====> Epoch: 57 TRAINING Loss: 2.493e-03  VALIDATION Loss: 2.584e-03
====> Epoch: 58 TRAINING Loss: 2.495e-03  VALIDATION Loss: 2.574e-03
====> Epoch: 59 TRAINING Loss: 2.470e-03  VALIDATION Loss: 2.514e-03
====> Epoch: 60 TRAINING Loss: 2.446e-03  VALIDATION Loss: 2.546e-03
====> Epoch: 61 TRAINING Loss: 2.409e-03  VALIDATION Loss: 2.451e-03
====> Epoch: 62 TRAINING Loss: 2.426e-03  VALIDATION Loss: 2.380e-03
====> Epoch: 63 TRAINING Loss: 2.403e-03  VALIDATION Loss: 2.797e-03
====> Epoch: 64 TRAINING Loss: 2.376e-03  VALIDATION Loss: 2.154e-03
====> Epoch: 65 TRAINING Loss: 2.403e-03  VALIDATION Loss: 2.316e-03
====> Epoch: 66 TRAINING Loss: 2.303e-03  VALIDATION Loss: 2.486e-03
====> Epoch: 67 TRAINING Loss: 2.343e-03  VALIDATION Loss: 2.940e-03
====> Epoch: 68 TRAINING Loss: 2.343e-03  VALIDATION Loss: 2.482e-03
====> Epoch: 69 TRAINING Loss: 2.318e-03  VALIDATION Loss: 2.220e-03
====> Epoch: 70 TRAINING Loss: 2.236e-03  VALIDATION Loss: 2.238e-03
====> Epoch: 71 TRAINING Loss: 2.281e-03  VALIDATION Loss: 2.348e-03
====> Epoch: 72 TRAINING Loss: 2.211e-03  VALIDATION Loss: 2.016e-03
====> Epoch: 73 TRAINING Loss: 2.143e-03  VALIDATION Loss: 2.504e-03
====> Epoch: 74 TRAINING Loss: 2.126e-03  VALIDATION Loss: 1.994e-03
====> Epoch: 75 TRAINING Loss: 2.115e-03  VALIDATION Loss: 2.098e-03
====> Epoch: 76 TRAINING Loss: 2.061e-03  VALIDATION Loss: 2.006e-03
====> Epoch: 77 TRAINING Loss: 2.087e-03  VALIDATION Loss: 1.865e-03
====> Epoch: 78 TRAINING Loss: 2.032e-03  VALIDATION Loss: 1.902e-03
====> Epoch: 79 TRAINING Loss: 2.101e-03  VALIDATION Loss: 1.792e-03
====> Epoch: 80 TRAINING Loss: 2.013e-03  VALIDATION Loss: 2.687e-03
====> Epoch: 81 TRAINING Loss: 1.959e-03  VALIDATION Loss: 1.738e-03
====> Epoch: 82 TRAINING Loss: 2.011e-03  VALIDATION Loss: 2.195e-03
====> Epoch: 83 TRAINING Loss: 1.987e-03  VALIDATION Loss: 1.877e-03
====> Epoch: 84 TRAINING Loss: 1.991e-03  VALIDATION Loss: 1.926e-03
====> Epoch: 85 TRAINING Loss: 1.877e-03  VALIDATION Loss: 1.756e-03
====> Epoch: 86 TRAINING Loss: 1.883e-03  VALIDATION Loss: 1.672e-03
====> Epoch: 87 TRAINING Loss: 1.794e-03  VALIDATION Loss: 1.668e-03
====> Epoch: 88 TRAINING Loss: 1.852e-03  VALIDATION Loss: 1.713e-03
====> Epoch: 89 TRAINING Loss: 1.775e-03  VALIDATION Loss: 1.552e-03
====> Epoch: 90 TRAINING Loss: 1.717e-03  VALIDATION Loss: 1.637e-03
====> Epoch: 91 TRAINING Loss: 1.820e-03  VALIDATION Loss: 1.803e-03
====> Epoch: 92 TRAINING Loss: 1.764e-03  VALIDATION Loss: 2.145e-03
====> Epoch: 93 TRAINING Loss: 1.727e-03  VALIDATION Loss: 1.731e-03
====> Epoch: 94 TRAINING Loss: 1.811e-03  VALIDATION Loss: 1.536e-03
====> Epoch: 95 TRAINING Loss: 1.698e-03  VALIDATION Loss: 1.644e-03
====> Epoch: 96 TRAINING Loss: 1.629e-03  VALIDATION Loss: 1.452e-03
====> Epoch: 97 TRAINING Loss: 1.667e-03  VALIDATION Loss: 1.649e-03
====> Epoch: 98 TRAINING Loss: 1.710e-03  VALIDATION Loss: 1.547e-03
====> Epoch: 99 TRAINING Loss: 1.603e-03  VALIDATION Loss: 1.544e-03
====> Epoch: 100 TRAINING Loss: 1.604e-03  VALIDATION Loss: 1.582e-03
====> Epoch: 101 TRAINING Loss: 1.669e-03  VALIDATION Loss: 1.544e-03
====> Epoch: 102 TRAINING Loss: 1.636e-03  VALIDATION Loss: 1.847e-03
====> Epoch: 103 TRAINING Loss: 1.593e-03  VALIDATION Loss: 1.642e-03
====> Epoch: 104 TRAINING Loss: 1.523e-03  VALIDATION Loss: 2.712e-03
====> Epoch: 105 TRAINING Loss: 1.628e-03  VALIDATION Loss: 1.731e-03
====> Epoch: 106 TRAINING Loss: 1.552e-03  VALIDATION Loss: 1.493e-03
====> Epoch: 107 TRAINING Loss: 1.567e-03  VALIDATION Loss: 1.633e-03
====> Epoch: 108 TRAINING Loss: 1.518e-03  VALIDATION Loss: 1.574e-03
====> Epoch: 109 TRAINING Loss: 1.523e-03  VALIDATION Loss: 1.811e-03
====> Epoch: 110 TRAINING Loss: 1.592e-03  VALIDATION Loss: 1.469e-03
====> Epoch: 111 TRAINING Loss: 1.502e-03  VALIDATION Loss: 1.367e-03
====> Epoch: 112 TRAINING Loss: 1.548e-03  VALIDATION Loss: 1.456e-03
====> Epoch: 113 TRAINING Loss: 1.476e-03  VALIDATION Loss: 1.530e-03
====> Epoch: 114 TRAINING Loss: 1.504e-03  VALIDATION Loss: 1.518e-03
====> Epoch: 115 TRAINING Loss: 1.556e-03  VALIDATION Loss: 1.426e-03
====> Epoch: 116 TRAINING Loss: 1.471e-03  VALIDATION Loss: 1.597e-03
====> Epoch: 117 TRAINING Loss: 1.510e-03  VALIDATION Loss: 1.405e-03
====> Epoch: 118 TRAINING Loss: 1.465e-03  VALIDATION Loss: 1.446e-03
====> Epoch: 119 TRAINING Loss: 1.516e-03  VALIDATION Loss: 1.605e-03
====> Epoch: 120 TRAINING Loss: 1.439e-03  VALIDATION Loss: 1.362e-03
====> Epoch: 121 TRAINING Loss: 1.436e-03  VALIDATION Loss: 1.352e-03
====> Epoch: 122 TRAINING Loss: 1.414e-03  VALIDATION Loss: 1.398e-03
====> Epoch: 123 TRAINING Loss: 1.527e-03  VALIDATION Loss: 1.374e-03
====> Epoch: 124 TRAINING Loss: 1.418e-03  VALIDATION Loss: 1.702e-03
====> Epoch: 125 TRAINING Loss: 1.433e-03  VALIDATION Loss: 1.337e-03
====> Epoch: 126 TRAINING Loss: 1.371e-03  VALIDATION Loss: 1.485e-03
====> Epoch: 127 TRAINING Loss: 1.390e-03  VALIDATION Loss: 1.576e-03
====> Epoch: 128 TRAINING Loss: 1.423e-03  VALIDATION Loss: 1.364e-03
====> Epoch: 129 TRAINING Loss: 1.378e-03  VALIDATION Loss: 1.540e-03
====> Epoch: 130 TRAINING Loss: 1.387e-03  VALIDATION Loss: 1.373e-03
====> Epoch: 131 TRAINING Loss: 1.386e-03  VALIDATION Loss: 1.338e-03
====> Epoch: 132 TRAINING Loss: 1.386e-03  VALIDATION Loss: 1.380e-03
====> Epoch: 133 TRAINING Loss: 1.340e-03  VALIDATION Loss: 1.249e-03
====> Epoch: 134 TRAINING Loss: 1.386e-03  VALIDATION Loss: 1.366e-03
====> Epoch: 135 TRAINING Loss: 1.358e-03  VALIDATION Loss: 1.282e-03
====> Epoch: 136 TRAINING Loss: 1.332e-03  VALIDATION Loss: 1.408e-03
====> Epoch: 137 TRAINING Loss: 1.362e-03  VALIDATION Loss: 1.350e-03
====> Epoch: 138 TRAINING Loss: 1.426e-03  VALIDATION Loss: 1.393e-03
====> Epoch: 139 TRAINING Loss: 1.346e-03  VALIDATION Loss: 1.306e-03
====> Epoch: 140 TRAINING Loss: 1.423e-03  VALIDATION Loss: 1.450e-03
====> Epoch: 141 TRAINING Loss: 1.327e-03  VALIDATION Loss: 1.348e-03
====> Epoch: 142 TRAINING Loss: 1.362e-03  VALIDATION Loss: 1.395e-03
====> Epoch: 143 TRAINING Loss: 1.311e-03  VALIDATION Loss: 1.695e-03
====> Epoch: 144 TRAINING Loss: 1.320e-03  VALIDATION Loss: 1.248e-03
====> Epoch: 145 TRAINING Loss: 1.299e-03  VALIDATION Loss: 1.251e-03
====> Epoch: 146 TRAINING Loss: 1.278e-03  VALIDATION Loss: 1.316e-03
====> Epoch: 147 TRAINING Loss: 1.270e-03  VALIDATION Loss: 1.245e-03
====> Epoch: 148 TRAINING Loss: 1.313e-03  VALIDATION Loss: 1.312e-03
====> Epoch: 149 TRAINING Loss: 1.276e-03  VALIDATION Loss: 1.237e-03
====> Epoch: 150 TRAINING Loss: 1.277e-03  VALIDATION Loss: 1.398e-03
====> Epoch: 151 TRAINING Loss: 1.233e-03  VALIDATION Loss: 1.334e-03
====> Epoch: 152 TRAINING Loss: 1.286e-03  VALIDATION Loss: 1.603e-03
====> Epoch: 153 TRAINING Loss: 1.316e-03  VALIDATION Loss: 1.213e-03
====> Epoch: 154 TRAINING Loss: 1.236e-03  VALIDATION Loss: 1.200e-03
====> Epoch: 155 TRAINING Loss: 1.288e-03  VALIDATION Loss: 1.197e-03
====> Epoch: 156 TRAINING Loss: 1.243e-03  VALIDATION Loss: 1.324e-03
====> Epoch: 157 TRAINING Loss: 1.283e-03  VALIDATION Loss: 1.245e-03
====> Epoch: 158 TRAINING Loss: 1.247e-03  VALIDATION Loss: 1.297e-03
====> Epoch: 159 TRAINING Loss: 1.247e-03  VALIDATION Loss: 1.190e-03
====> Epoch: 160 TRAINING Loss: 1.251e-03  VALIDATION Loss: 1.235e-03
====> Epoch: 161 TRAINING Loss: 1.252e-03  VALIDATION Loss: 1.390e-03
====> Epoch: 162 TRAINING Loss: 1.230e-03  VALIDATION Loss: 1.223e-03
====> Epoch: 163 TRAINING Loss: 1.205e-03  VALIDATION Loss: 1.328e-03
====> Epoch: 164 TRAINING Loss: 1.211e-03  VALIDATION Loss: 1.268e-03
====> Epoch: 165 TRAINING Loss: 1.225e-03  VALIDATION Loss: 1.218e-03
====> Epoch: 166 TRAINING Loss: 1.189e-03  VALIDATION Loss: 1.319e-03
====> Epoch: 167 TRAINING Loss: 1.222e-03  VALIDATION Loss: 1.218e-03
====> Epoch: 168 TRAINING Loss: 1.202e-03  VALIDATION Loss: 1.201e-03
====> Epoch: 169 TRAINING Loss: 1.172e-03  VALIDATION Loss: 1.162e-03
====> Epoch: 170 TRAINING Loss: 1.197e-03  VALIDATION Loss: 1.193e-03
====> Epoch: 171 TRAINING Loss: 1.195e-03  VALIDATION Loss: 1.177e-03
====> Epoch: 172 TRAINING Loss: 1.192e-03  VALIDATION Loss: 1.165e-03
====> Epoch: 173 TRAINING Loss: 1.193e-03  VALIDATION Loss: 1.178e-03
====> Epoch: 174 TRAINING Loss: 1.176e-03  VALIDATION Loss: 1.215e-03
====> Epoch: 175 TRAINING Loss: 1.192e-03  VALIDATION Loss: 1.213e-03
====> Epoch: 176 TRAINING Loss: 1.171e-03  VALIDATION Loss: 1.220e-03
====> Epoch: 177 TRAINING Loss: 1.175e-03  VALIDATION Loss: 1.172e-03
====> Epoch: 178 TRAINING Loss: 1.157e-03  VALIDATION Loss: 1.199e-03
====> Epoch: 179 TRAINING Loss: 1.180e-03  VALIDATION Loss: 1.184e-03
====> Epoch: 180 TRAINING Loss: 1.185e-03  VALIDATION Loss: 1.146e-03
====> Epoch: 181 TRAINING Loss: 1.194e-03  VALIDATION Loss: 1.141e-03
====> Epoch: 182 TRAINING Loss: 1.154e-03  VALIDATION Loss: 1.236e-03
====> Epoch: 183 TRAINING Loss: 1.156e-03  VALIDATION Loss: 1.162e-03
====> Epoch: 184 TRAINING Loss: 1.156e-03  VALIDATION Loss: 1.130e-03
====> Epoch: 185 TRAINING Loss: 1.142e-03  VALIDATION Loss: 1.172e-03
====> Epoch: 186 TRAINING Loss: 1.132e-03  VALIDATION Loss: 1.129e-03
====> Epoch: 187 TRAINING Loss: 1.125e-03  VALIDATION Loss: 1.145e-03
====> Epoch: 188 TRAINING Loss: 1.121e-03  VALIDATION Loss: 1.116e-03
====> Epoch: 189 TRAINING Loss: 1.148e-03  VALIDATION Loss: 1.155e-03
====> Epoch: 190 TRAINING Loss: 1.153e-03  VALIDATION Loss: 1.170e-03
====> Epoch: 191 TRAINING Loss: 1.136e-03  VALIDATION Loss: 1.126e-03
====> Epoch: 192 TRAINING Loss: 1.100e-03  VALIDATION Loss: 1.130e-03
====> Epoch: 193 TRAINING Loss: 1.113e-03  VALIDATION Loss: 1.101e-03
====> Epoch: 194 TRAINING Loss: 1.120e-03  VALIDATION Loss: 1.149e-03
====> Epoch: 195 TRAINING Loss: 1.137e-03  VALIDATION Loss: 1.123e-03
====> Epoch: 196 TRAINING Loss: 1.096e-03  VALIDATION Loss: 1.157e-03
====> Epoch: 197 TRAINING Loss: 1.120e-03  VALIDATION Loss: 1.099e-03
====> Epoch: 198 TRAINING Loss: 1.108e-03  VALIDATION Loss: 1.191e-03
====> Epoch: 199 TRAINING Loss: 1.093e-03  VALIDATION Loss: 1.112e-03
====> Epoch: 200 TRAINING Loss: 1.121e-03  VALIDATION Loss: 1.134e-03
====> Epoch: 201 TRAINING Loss: 1.090e-03  VALIDATION Loss: 1.100e-03
====> Epoch: 202 TRAINING Loss: 1.080e-03  VALIDATION Loss: 1.156e-03
====> Epoch: 203 TRAINING Loss: 1.089e-03  VALIDATION Loss: 1.111e-03
====> Epoch: 204 TRAINING Loss: 1.094e-03  VALIDATION Loss: 1.110e-03
====> Epoch: 205 TRAINING Loss: 1.084e-03  VALIDATION Loss: 1.107e-03
====> Epoch: 206 TRAINING Loss: 1.069e-03  VALIDATION Loss: 1.093e-03
====> Epoch: 207 TRAINING Loss: 1.064e-03  VALIDATION Loss: 1.093e-03
====> Epoch: 208 TRAINING Loss: 1.073e-03  VALIDATION Loss: 1.128e-03
====> Epoch: 209 TRAINING Loss: 1.090e-03  VALIDATION Loss: 1.090e-03
====> Epoch: 210 TRAINING Loss: 1.092e-03  VALIDATION Loss: 1.085e-03
====> Epoch: 211 TRAINING Loss: 1.063e-03  VALIDATION Loss: 1.087e-03
====> Epoch: 212 TRAINING Loss: 1.064e-03  VALIDATION Loss: 1.095e-03
====> Epoch: 213 TRAINING Loss: 1.066e-03  VALIDATION Loss: 1.080e-03
====> Epoch: 214 TRAINING Loss: 1.075e-03  VALIDATION Loss: 1.083e-03
====> Epoch: 215 TRAINING Loss: 1.054e-03  VALIDATION Loss: 1.078e-03
====> Epoch: 216 TRAINING Loss: 1.063e-03  VALIDATION Loss: 1.069e-03
====> Epoch: 217 TRAINING Loss: 1.049e-03  VALIDATION Loss: 1.081e-03
====> Epoch: 218 TRAINING Loss: 1.049e-03  VALIDATION Loss: 1.077e-03
====> Epoch: 219 TRAINING Loss: 1.055e-03  VALIDATION Loss: 1.057e-03
====> Epoch: 220 TRAINING Loss: 1.044e-03  VALIDATION Loss: 1.066e-03
====> Epoch: 221 TRAINING Loss: 1.043e-03  VALIDATION Loss: 1.081e-03
====> Epoch: 222 TRAINING Loss: 1.047e-03  VALIDATION Loss: 1.070e-03
====> Epoch: 223 TRAINING Loss: 1.049e-03  VALIDATION Loss: 1.057e-03
====> Epoch: 224 TRAINING Loss: 1.038e-03  VALIDATION Loss: 1.060e-03
====> Epoch: 225 TRAINING Loss: 1.041e-03  VALIDATION Loss: 1.055e-03
====> Epoch: 226 TRAINING Loss: 1.050e-03  VALIDATION Loss: 1.070e-03
====> Epoch: 227 TRAINING Loss: 1.060e-03  VALIDATION Loss: 1.055e-03
====> Epoch: 228 TRAINING Loss: 1.032e-03  VALIDATION Loss: 1.074e-03
====> Epoch: 229 TRAINING Loss: 1.042e-03  VALIDATION Loss: 1.053e-03
====> Epoch: 230 TRAINING Loss: 1.027e-03  VALIDATION Loss: 1.055e-03
====> Epoch: 231 TRAINING Loss: 1.059e-03  VALIDATION Loss: 1.049e-03
====> Epoch: 232 TRAINING Loss: 1.031e-03  VALIDATION Loss: 1.059e-03
====> Epoch: 233 TRAINING Loss: 1.041e-03  VALIDATION Loss: 1.047e-03
====> Epoch: 234 TRAINING Loss: 1.036e-03  VALIDATION Loss: 1.046e-03
====> Epoch: 235 TRAINING Loss: 1.037e-03  VALIDATION Loss: 1.054e-03
====> Epoch: 236 TRAINING Loss: 1.017e-03  VALIDATION Loss: 1.048e-03
====> Epoch: 237 TRAINING Loss: 1.033e-03  VALIDATION Loss: 1.048e-03
====> Epoch: 238 TRAINING Loss: 1.046e-03  VALIDATION Loss: 1.047e-03
====> Epoch: 239 TRAINING Loss: 1.027e-03  VALIDATION Loss: 1.049e-03
====> Epoch: 240 TRAINING Loss: 1.016e-03  VALIDATION Loss: 1.044e-03
====> Epoch: 241 TRAINING Loss: 1.026e-03  VALIDATION Loss: 1.044e-03
====> Epoch: 242 TRAINING Loss: 1.021e-03  VALIDATION Loss: 1.048e-03
====> Epoch: 243 TRAINING Loss: 1.025e-03  VALIDATION Loss: 1.043e-03
====> Epoch: 244 TRAINING Loss: 1.021e-03  VALIDATION Loss: 1.042e-03
====> Epoch: 245 TRAINING Loss: 1.036e-03  VALIDATION Loss: 1.043e-03
====> Epoch: 246 TRAINING Loss: 1.026e-03  VALIDATION Loss: 1.044e-03
====> Epoch: 247 TRAINING Loss: 1.038e-03  VALIDATION Loss: 1.041e-03
====> Epoch: 248 TRAINING Loss: 1.021e-03  VALIDATION Loss: 1.046e-03
====> Epoch: 249 TRAINING Loss: 1.019e-03  VALIDATION Loss: 1.041e-03
Training has finished in  11109.811987161636  s
Model saved
n_epochs: 250, batch_size: 128, lr: 5e-04
Modules prepared
cuda:0  prepared
Loading data...
Shuffling...
Dataset prepared
16 components selected for the latent vectors
Shape of the test set:  (15000, 1978)
Calling accelerator...
DistributedType.NO
Loading model...
Testing starts now...
Saving latents and predicted percentiles...
Loading modules
cuda:0  prepared
Loading data...
Creating dataset and calling accelerator
Shape of the dataset:  (150000, 1978)
Loading module trained with latents of  16  components
Getting latent vectors and predicted percentiles
Saving spectra, percentiles, latents and predicted percentiles
